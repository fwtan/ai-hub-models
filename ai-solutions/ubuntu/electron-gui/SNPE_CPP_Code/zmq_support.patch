diff --git a/examples/SNPE/NativeCpp/SampleCode/jni/CMakeLists.txt b/examples/SNPE/NativeCpp/SampleCode/jni/CMakeLists.txt
new file mode 100644
index 0000000..a98e623
--- /dev/null
+++ b/examples/SNPE/NativeCpp/SampleCode/jni/CMakeLists.txt
@@ -0,0 +1,57 @@
+#==============================================================================
+#
+#  Copyright (c) 2020-2023 Qualcomm Technologies, Inc.
+#  All Rights Reserved.
+#  Confidential and Proprietary - Qualcomm Technologies, Inc.
+#
+#==============================================================================
+
+cmake_minimum_required (VERSION 3.14)
+project (snpe-sample)
+set (APP "snpe-sample")
+
+set( APP_SOURCES
+    "main.cpp"
+    "Util.cpp"
+    "SetBuilderOptions.cpp"
+    "SetBuilderOptions.hpp"
+    "SaveOutputTensor.cpp"
+    "SaveOutputTensor.hpp"
+    "Util.hpp"
+    "NV21Load.cpp"
+    "NV21Load.hpp"
+    "LoadInputTensor.cpp"
+    "LoadInputTensor.hpp"
+    "CheckRuntime.cpp"
+    "CheckRuntime.hpp"
+    "LoadContainer.cpp"
+    "LoadContainer.hpp"
+    "PreprocessInput.cpp"
+    "PreprocessInput.hpp"
+    "CreateUserBuffer.cpp"
+    "CreateUserBuffer.hpp"
+)
+
+set (SNPE_ROOT "/opt/qcom/aistack/snpe/2.13.0.230730/")
+set (SNPE_INCLUDE_DIR "${SNPE_ROOT}/include/SNPE")
+set (SNPE_LIB_PREFIX "${SNPE_ROOT}/lib")
+set (_dtuple_POSTFIX ubuntu-gcc7.5)
+
+set (RELEASE "Release/")
+
+message("Linking with ARM64 SNPE")
+get_filename_component(SNPE_SO_PATH "${SNPE_LIB_PREFIX}/aarch64-${_dtuple_POSTFIX}/libSNPE.so" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+
+add_library( SNPE SHARED IMPORTED )
+set_target_properties(SNPE PROPERTIES
+	IMPORTED_LOCATION ${SNPE_SO_PATH}
+	INTERFACE_INCLUDE_DIRECTORIES ${SNPE_INCLUDE_DIR}
+)
+
+add_executable(${APP} ${APP_SOURCES})
+target_compile_definitions(${APP} PUBLIC -D_CRT_SECURE_NO_WARNINGS)
+target_link_libraries (${APP} SNPE zmq)
+add_custom_command(TARGET ${APP} POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy_if_different
+    ${APP}
+    ${RELEASE})
diff --git a/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.cpp b/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.cpp
index fa500e5..3091e64 100644
--- a/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.cpp
+++ b/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.cpp
@@ -25,7 +25,7 @@
 #include "DlSystem/UserBufferMap.hpp"
 
 void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
-                      std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                      std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                       std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                       std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                       const char * name,
@@ -83,7 +83,7 @@ void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
    }
 
    // create user-backed storage to load input data onto it
-   applicationBuffers.emplace(name, std::vector<uint8_t>(bufSize));
+   applicationBuffers.emplace(name, std::vector<float>(bufSize));
 
    // create SNPE user buffer from the user-backed buffer
    zdl::DlSystem::IUserBufferFactory& ubFactory = zdl::SNPE::SNPEFactory::getUserBufferFactory();
@@ -100,7 +100,7 @@ void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
 }
 
 void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
-                          std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                          std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                           std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                           std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                           bool isTfNBuffer,
@@ -120,7 +120,7 @@ void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
 }
 
 void createOutputBufferMap(zdl::DlSystem::UserBufferMap& outputMap,
-                           std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                           std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                            std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                            std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                            bool isTfNBuffer,
diff --git a/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.hpp b/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.hpp
index 138a7c4..d2129c3 100644
--- a/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.hpp
+++ b/examples/SNPE/NativeCpp/SampleCode/jni/CreateUserBuffer.hpp
@@ -18,7 +18,7 @@ typedef unsigned int GLuint;
 
 // Helper function to fill a single entry of the UserBufferMap with the given user-backed buffer
 void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
-                      std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                      std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                       std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                       std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                       const char * name,
@@ -28,7 +28,7 @@ void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
 
 // Create a UserBufferMap of the SNPE network inputs
 void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
-                          std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                          std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                           std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                           std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                           const bool isTfNBuffer,
@@ -37,7 +37,7 @@ void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
 
 // Create a UserBufferMap of the SNPE network outputs
 void createOutputBufferMap(zdl::DlSystem::UserBufferMap& outputMap,
-                           std::unordered_map<std::string, std::vector<uint8_t>>& applicationBuffers,
+                           std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
                            std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                            std::unique_ptr<zdl::SNPE::SNPE>& snpe,
                            const bool isTfNBuffer,
diff --git a/examples/SNPE/NativeCpp/SampleCode/jni/SetBuilderOptions.cpp b/examples/SNPE/NativeCpp/SampleCode/jni/SetBuilderOptions.cpp
index fde8337..6cf7927 100644
--- a/examples/SNPE/NativeCpp/SampleCode/jni/SetBuilderOptions.cpp
+++ b/examples/SNPE/NativeCpp/SampleCode/jni/SetBuilderOptions.cpp
@@ -33,6 +33,7 @@ std::unique_ptr<zdl::SNPE::SNPE> setBuilderOptions(std::unique_ptr<zdl::DlContai
        .setPlatformConfig(platformConfig)
        .setInitCacheMode(useCaching)
        .setCpuFixedPointMode(cpuFixedPointMode)
+       .setUnconsumedTensorsAsOutputs(true)
        .build();
     return snpe;
 }
diff --git a/examples/SNPE/NativeCpp/SampleCode/jni/main.cpp b/examples/SNPE/NativeCpp/SampleCode/jni/main.cpp
index 2d4117c..17dff84 100644
--- a/examples/SNPE/NativeCpp/SampleCode/jni/main.cpp
+++ b/examples/SNPE/NativeCpp/SampleCode/jni/main.cpp
@@ -10,10 +10,8 @@
 // network using the SNPE C++ API and saves the layer output to a file.
 // Inputs to and outputs from the network are conveyed in binary form as single
 // precision floating point values.
-//
-#include <cstring>
+
 #include <iostream>
-#include <getopt.h>
 #include <fstream>
 #include <cstdlib>
 #include <vector>
@@ -21,10 +19,11 @@
 #include <iterator>
 #include <unordered_map>
 #include <algorithm>
+#include <zmq.hpp>
+#include <chrono>
 
 #include "CheckRuntime.hpp"
 #include "LoadContainer.hpp"
-#include "LoadUDOPackage.hpp"
 #include "SetBuilderOptions.hpp"
 #include "LoadInputTensor.hpp"
 #include "CreateUserBuffer.hpp"
@@ -33,246 +32,75 @@
 #include "Util.hpp"
 #include "DlSystem/DlError.hpp"
 #include "DlSystem/RuntimeList.hpp"
-#ifdef ENABLE_GL_BUFFER
-#include <GLES2/gl2.h>
-#include "CreateGLBuffer.hpp"
-#endif
-
 #include "DlSystem/UserBufferMap.hpp"
 #include "DlSystem/IUserBuffer.hpp"
 #include "DlContainer/IDlContainer.hpp"
 #include "SNPE/SNPE.hpp"
-#include "SNPE/SNPEFactory.hpp"
-#include "DiagLog/IDiagLog.hpp"
 
 const int FAILURE = 1;
 const int SUCCESS = 0;
 
-int main(int argc, char** argv)
+enum { UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16 };
+enum { CPUBUFFER, GLBUFFER };
+bool useUserSuppliedBuffers = false;
+int bufferType;
+int bitWidth = 0;
+int MAX_PATH=128;
+
+std::unique_ptr<zdl::SNPE::SNPE> build_network(std::string dlc, zdl::DlSystem::Runtime_t runtime, bool runtimeSpecified, bool usingInitCaching, std::string bufferTypeStr, std::string userBufferSourceStr, std::string staticQuantizationStr)
 {
-    enum {UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16};
-    enum {CPUBUFFER, GLBUFFER};
 
-    // Command line arguments
-    static std::string dlc = "";
-    static std::string OutputDir = "./output/";
-    const char* inputFile = "";
-    std::string bufferTypeStr = "ITENSOR";
-    std::string userBufferSourceStr = "CPUBUFFER";
-    std::string staticQuantizationStr = "false";
-    static zdl::DlSystem::Runtime_t runtime = zdl::DlSystem::Runtime_t::CPU;
-    static zdl::DlSystem::RuntimeList runtimeList;
-    bool runtimeSpecified = false;
-    bool execStatus = false;
-    bool usingInitCaching = false;
-    bool staticQuantization = false;
-    bool cpuFixedPointMode = false;
-    std::string UdoPackagePath = "";
-
-#ifdef __ANDROID__
-    // Initialize Logs with level LOG_ERROR.
-    zdl::SNPE::SNPEFactory::initializeLogging(zdl::DlSystem::LogLevel_t::LOG_ERROR);
-#else
-    // Initialize Logs with specified log level as LOG_ERROR and log path as "./Log".
-    zdl::SNPE::SNPEFactory::initializeLogging(zdl::DlSystem::LogLevel_t::LOG_ERROR, "./Log");
-#endif
-
-    // Update Log Level to LOG_WARN.
-    zdl::SNPE::SNPEFactory::setLogLevel(zdl::DlSystem::LogLevel_t::LOG_WARN);
-
-    // Process command line arguments
-    int opt = 0;
-    while ((opt = getopt(argc, argv, "hi:d:o:b:q:s:z:r:l:u:c:x")) != -1)
+    zdl::DlSystem::RuntimeList runtimeList;
+    bool staticQuantization;
+	bool cpuFixedPointMode = false;
+
+    if (staticQuantizationStr == "true")
     {
-        switch (opt)
-        {
-            case 'h':
-                std::cout
-                        << "\nDESCRIPTION:\n"
-                        << "------------\n"
-                        << "Example application demonstrating how to load and execute a neural network\n"
-                        << "using the SNPE C++ API.\n"
-                        << "\n\n"
-                        << "REQUIRED ARGUMENTS:\n"
-                        << "-------------------\n"
-                        << "  -d  <FILE>   Path to the DL container containing the network.\n"
-                        << "  -i  <FILE>   Path to a file listing the inputs for the network.\n"
-                        << "  -o  <PATH>   Path to directory to store output results.\n"
-                        << "\n"
-                        << "OPTIONAL ARGUMENTS:\n"
-                        << "-------------------\n"
-                        << "  -b  <TYPE>   Type of buffers to use [USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16] (" << bufferTypeStr << " is default).\n"
-                        << "  -q  <BOOL>    Specifies to use static quantization parameters from the model instead of input specific quantization [true, false]. Used in conjunction with USERBUFFER_TF8. \n"
-                        << "  -r  <RUNTIME> The runtime to be used [gpu, dsp, aip, cpu] (cpu is default). \n"
-                        << "  -u  <VAL,VAL> Path to UDO package with registration library for UDOs. \n"
-                        << "                Optionally, user can provide multiple packages as a comma-separated list. \n"
-                        << "  -z  <NUMBER>  The maximum number that resizable dimensions can grow into. \n"
-                        << "                Used as a hint to create UserBuffers for models with dynamic sized outputs. Should be a positive integer and is not applicable when using ITensor. \n"
-#ifdef ENABLE_GL_BUFFER
-                        << "  -s  <TYPE>   Source of user buffers to use [GLBUFFER, CPUBUFFER] (" << userBufferSourceStr << " is default).\n"
-#endif
-                        << "  -c           Enable init caching to accelerate the initialization process of SNPE. Defaults to disable.\n"
-                        << "  -l  <VAL,VAL,VAL> Specifies the order of precedence for runtime e.g  cpu_float32, dsp_fixed8_tf etc. Valid values are:- \n"
-                        << "                    cpu_float32 (Snapdragon CPU)       = Data & Math: float 32bit \n"
-                        << "                    gpu_float32_16_hybrid (Adreno GPU) = Data: float 16bit Math: float 32bit \n"
-                        << "                    dsp_fixed8_tf (Hexagon DSP)        = Data & Math: 8bit fixed point Tensorflow style format \n"
-                        << "                    gpu_float16 (Adreno GPU)           = Data: float 16bit Math: float 16bit \n"
-#if DNN_RUNTIME_HAVE_AIP_RUNTIME
-                        << "                    aip_fixed8_tf (Snapdragon HTA+HVX) = Data & Math: 8bit fixed point Tensorflow style format \n"
-
-#endif
-                        << "                    cpu (Snapdragon CPU)               = Same as cpu_float32 \n"
-                        << "                    gpu (Adreno GPU)                   = Same as gpu_float32_16_hybrid \n"
-                        << "                    dsp (Hexagon DSP)                  = Same as dsp_fixed8_tf \n"
-#if DNN_RUNTIME_HAVE_AIP_RUNTIME
-                        << "                    aip (Snapdragon HTA+HVX)           = Same as aip_fixed8_tf \n"
-#endif
-                        << "  -x            Specifies to use the fixed point execution on CPU runtime for quantized DLC.\n"
-                        << "                Used in conjunction with CPU runtime.\n"
-                        << std::endl;
-
-                std::exit(SUCCESS);
-            case 'i':
-                inputFile = optarg;
-                break;
-            case 'd':
-                dlc = optarg;
-                break;
-            case 'o':
-                OutputDir = optarg;
-                break;
-            case 'b':
-                bufferTypeStr = optarg;
-                break;
-            case 'q':
-                staticQuantizationStr = optarg;
-                break;
-            case 's':
-                userBufferSourceStr = optarg;
-                break;
-            case 'z':
-                setResizableDim(atoi(optarg));
-                break;
-            case 'r':
-                runtimeSpecified = true;
-                if (strcmp(optarg, "gpu") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::GPU;
-                }
-                else if (strcmp(optarg, "aip") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::AIP_FIXED8_TF;
-                }
-                else if (strcmp(optarg, "dsp") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::DSP;
-                }
-                else if (strcmp(optarg, "cpu") == 0)
-                {
-                   runtime = zdl::DlSystem::Runtime_t::CPU;
-                }
-                else
-                {
-                   std::cerr << "The runtime option provide is not valid. Defaulting to the CPU runtime." << std::endl;
-
-                }
-                break;
-
-            case 'l':
-                {
-                   std::string inputString = optarg;
-                   //std::cout<<"Input String: "<<inputString<<std::endl;
-                   std::vector<std::string> runtimeStrVector;
-                   split(runtimeStrVector, inputString, ',');
-
-                   //Check for dups
-                   for(auto it = runtimeStrVector.begin(); it != runtimeStrVector.end()-1; it++)
-                   {
-                      auto found = std::find(it+1, runtimeStrVector.end(), *it);
-                      if(found != runtimeStrVector.end())
-                      {
-                         std::cerr << "Error: Invalid values passed to the argument "<< argv[optind-2] << ". Duplicate entries in runtime order" << std::endl;
-                         std::exit(FAILURE);
-                      }
-                   }
-
-                   runtimeList.clear();
-                   for(auto& runtimeStr : runtimeStrVector)
-                   {
-                      //std::cout<<runtimeStr<<std::endl;
-                      zdl::DlSystem::Runtime_t runtime = zdl::DlSystem::RuntimeList::stringToRuntime(runtimeStr.c_str());
-                      if(runtime != zdl::DlSystem::Runtime_t::UNSET)
-                      {
-                         bool ret = runtimeList.add(runtime);
-                         if(ret == false)
-                         {
-                            std::cerr <<zdl::DlSystem::getLastErrorString()<<std::endl;
-                            std::cerr << "Error: Invalid values passed to the argument "<< argv[optind-2] << ". Please provide comma seperated runtime order of precedence" << std::endl;
-                            std::exit(FAILURE);
-                         }
-                      }
-                      else
-                      {
-                         std::cerr << "Error: Invalid values passed to the argument "<< argv[optind-2] << ". Please provide comma seperated runtime order of precedence" << std::endl;
-                         std::exit(FAILURE);
-                      }
-                   }
-                }
-                break;
-
-            case 'c':
-               usingInitCaching = true;
-               break;
-            case 'u':
-                UdoPackagePath = optarg;
-                break;
-            case 'x':
-               cpuFixedPointMode = true;
-               break;
-            default:
-                std::cout << "Invalid parameter specified. Please run snpe-sample with the -h flag to see required arguments" << std::endl;
-                std::exit(FAILURE);
-        }
+        staticQuantization = true;
     }
-
+    else if (staticQuantizationStr == "false")
+    {
+        staticQuantization = false;
+    }
+    else
+    {
+        std::cout << "Static quantization value is not valid. Please run snpe-sample with the -h flag for more details"
+            << std::endl;
+        return nullptr;
+    }
+	
+	if(runtimeList.empty()==false)
+	{
+		std::cout<<"\nruntimelist not empty";
+	}
+	
+	if(runtimeSpecified)
+	{
+		std::cout<<"\nruntime is specificed";
+	}
+    
     // Check if given arguments represent valid files
     std::ifstream dlcFile(dlc);
-    std::ifstream inputList(inputFile);
-    if (!dlcFile || !inputList) {
-        std::cout << "Input list or dlc file not valid. Please ensure that you have provided a valid input list and dlc for processing. Run snpe-sample with the -h flag for more details" << std::endl;
-        return EXIT_FAILURE;
+	if (!dlcFile) {
+        std::cout << "\nInput list or dlc file not valid. Please ensure that you have provided a valid input list and dlc for processing. Run snpe-sample with the -h flag for more details" << std::endl;
+        return nullptr;
     }
-
+    
     // Check if given buffer type is valid
-    int bufferType;
-    int bitWidth = 0;
     if (bufferTypeStr == "USERBUFFER_FLOAT")
     {
         bufferType = USERBUFFER_FLOAT;
     }
-    else if (bufferTypeStr == "USERBUFFER_TF8")
-    {
-        bufferType = USERBUFFER_TF8;
-        bitWidth = 8;
-    }
-    else if (bufferTypeStr == "USERBUFFER_TF16")
-    {
-        bufferType = USERBUFFER_TF16;
-        bitWidth = 16;
-    }
-    else if (bufferTypeStr == "ITENSOR")
-    {
-        bufferType = ITENSOR;
-    }
     else
     {
-        std::cout << "Buffer type is not valid. Please run snpe-sample with the -h flag for more details" << std::endl;
-        return EXIT_FAILURE;
+        std::cout << "\nBuffer type is not valid. Please run snpe-sample with the -h flag for more details" << std::endl;
+        return nullptr;
     }
 
     //Check if given user buffer source type is valid
     int userBufferSourceType;
-    // CPUBUFFER / GLBUFFER supported only for USERBUFFER_FLOAT
+    
+	// CPUBUFFER / GLBUFFER supported only for USERBUFFER_FLOAT
     if (bufferType == USERBUFFER_FLOAT)
     {
         if( userBufferSourceStr == "CPUBUFFER" )
@@ -281,312 +109,314 @@ int main(int argc, char** argv)
         }
         else if( userBufferSourceStr == "GLBUFFER" )
         {
-#ifndef ENABLE_GL_BUFFER
-            std::cout << "GLBUFFER mode is only supported on Android OS" << std::endl;
-            return EXIT_FAILURE;
-#endif
+            std::cout << "\nGLBUFFER mode is only supported on Android OS" << std::endl;
+            return nullptr;
             userBufferSourceType = GLBUFFER;
         }
         else
         {
             std::cout
-                  << "Source of user buffer type is not valid. Please run snpe-sample with the -h flag for more details"
+                  << "\nSource of user buffer type is not valid. Please run snpe-sample with the -h flag for more details"
                   << std::endl;
-            return EXIT_FAILURE;
+            return nullptr;
         }
     }
 
-    if (staticQuantizationStr == "true")
-    {
-        staticQuantization = true;
-    }
-    else if (staticQuantizationStr == "false")
-    {
-        staticQuantization = false;
-    }
-    else
-    {
-        std::cout << "Static quantization value is not valid. Please run snpe-sample with the -h flag for more details"
-             << std::endl;
-        return EXIT_FAILURE;
-    }
+   if (staticQuantizationStr == "true")
+   {
+      staticQuantization = true;
+   }
+   else if (staticQuantizationStr == "false")
+   {
+      staticQuantization = false;
+   }
+   else
+   {
+      std::cout << "\nStatic quantization value is not valid. Please run snpe-sample with the -h flag for more details"
+                << std::endl;
+      return nullptr;
+   }
 
     //Check if both runtimelist and runtime are passed in
-    if(runtimeSpecified && runtimeList.empty() == false)
+    if(runtimeSpecified && (runtimeList.empty() == false))
     {
-        std::cout << "Invalid option cannot mix runtime order -l with runtime -r " << std::endl;
+        std::cout << "\nInvalid option cannot mix runtime order -l with runtime -r " << std::endl;
         std::exit(FAILURE);
     }
-
-    // Open the DL container that contains the network to execute.
-    // Create an instance of the SNPE network from the now opened container.
-    // The factory functions provided by SNPE allow for the specification
-    // of which layers of the network should be returned as output and also
-    // if the network should be run on the CPU or GPU.
-    // The runtime availability API allows for runtime support to be queried.
-    // If a selected runtime is not available, we will issue a warning and continue,
-    // expecting the invalid configuration to be caught at SNPE network creation.
-
+    
     if(runtimeSpecified)
     {
         runtime = checkRuntime(runtime, staticQuantization);
+		std::cout<<"runtime is checked ";
+
+	 	std::vector<std::string> runtimeStrVector;
+
+		switch (runtime)
+		{
+			case zdl::DlSystem::Runtime_t::DSP:
+				runtimeStrVector.push_back("dsp_fixed8_tf");
+				runtimeStrVector.push_back("cpu_float32");
+				break;
+			case zdl::DlSystem::Runtime_t::CPU:
+			default:
+				runtimeStrVector.push_back("cpu_float32");
+				runtimeStrVector.push_back("dsp_fixed8_tf");
+				break;
+		}
+    
+		runtimeList.clear();
+		for(auto& runtimeStr : runtimeStrVector)
+		{
+			zdl::DlSystem::Runtime_t runtime = zdl::DlSystem::RuntimeList::stringToRuntime(runtimeStr.c_str());
+			if(runtime != zdl::DlSystem::Runtime_t::UNSET)
+			{
+				bool ret = runtimeList.add(runtime);
+				if(ret == false)
+				{
+					std::cerr <<zdl::DlSystem::getLastErrorString()<<std::endl;
+					std::cerr << "Error: runtime order of precedence" << std::endl;
+					std::exit(FAILURE);
+				}
+			}
+			else
+			{
+				std::cerr << "Error: Invalid values passed to the runtime order of precedence" << std::endl;
+				std::exit(FAILURE);
+			}
+		}
     }
 
     std::unique_ptr<zdl::DlContainer::IDlContainer> container = loadContainerFromFile(dlc);
     if (container == nullptr)
     {
        std::cerr << "Error while opening the container file." << std::endl;
-       return EXIT_FAILURE;
+       return nullptr;
     }
 
-    bool useUserSuppliedBuffers = (bufferType == USERBUFFER_FLOAT || bufferType == USERBUFFER_TF8 || bufferType == USERBUFFER_TF16);
+    useUserSuppliedBuffers = (bufferType == USERBUFFER_FLOAT ||
+                                   bufferType == USERBUFFER_TF8 ||
+                                   bufferType == USERBUFFER_TF16);
 
     std::unique_ptr<zdl::SNPE::SNPE> snpe;
     zdl::DlSystem::PlatformConfig platformConfig;
-#ifdef ENABLE_GL_BUFFER
-    CreateGLBuffer* glBuffer = nullptr;
-    if (userBufferSourceType == GLBUFFER) {
-        if(!checkGLCLInteropSupport()) {
-            std::cerr << "Failed to get gl cl shared library" << std::endl;
-            return EXIT_FAILURE;
-        }
-        glBuffer = new CreateGLBuffer();
-        glBuffer->setGPUPlatformConfig(platformConfig);
-    }
-#endif
 
-    //load UDO package
-    if(false == loadUDOPackage(UdoPackagePath))
-    {
-        std::cerr << "Failed to load UDO Package(s)." << std::endl;
-        return EXIT_FAILURE;
-    }
+    snpe = setBuilderOptions(container, runtime, runtimeList, useUserSuppliedBuffers, platformConfig, usingInitCaching,cpuFixedPointMode);
+	return snpe;
 
-    snpe = setBuilderOptions(container, runtime, runtimeList,
-                             useUserSuppliedBuffers, platformConfig,
-                             usingInitCaching, cpuFixedPointMode);
-    if (snpe == nullptr)
-    {
-       std::cerr << "Error while building SNPE object." << std::endl;
-       return EXIT_FAILURE;
-    }
-    if (usingInitCaching)
-    {
-       if (container->save(dlc))
-       {
-          std::cout << "Saved container into archive successfully" << std::endl;
-       }
-       else
-       {
-          std::cout << "Failed to save container into archive" << std::endl;
-       }
-    }
+}
+int main()
+{
+    // Initialize a ZeroMQ context
+    zmq::context_t context(1);
 
-    // Configure logging output and start logging. The snpe-diagview
-    // executable can be used to read the content of this diagnostics file
-    auto logger_opt = snpe->getDiagLogInterface();
-    if (!logger_opt) throw std::runtime_error("SNPE failed to obtain logging interface");
-    auto logger = *logger_opt;
-    auto opts = logger->getOptions();
-
-    opts.LogFileDirectory = OutputDir;
-    if(!logger->setOptions(opts)) {
-        std::cerr << "Failed to set options" << std::endl;
-        return EXIT_FAILURE;
-    }
-    if (!logger->start()) {
-        std::cerr << "Failed to start logger" << std::endl;
-        return EXIT_FAILURE;
-    }
+    // Create a REP (reply) socket
+    zmq::socket_t socket(context, ZMQ_REP);
+    // zmq::socket_t socket(context, ZMQ_PULL);
 
-    // Check the batch size for the container
-    // SNPE 1.16.0 (and newer) assumes the first dimension of the tensor shape
-    // is the batch size.
-    zdl::DlSystem::TensorShape tensorShape;
-    tensorShape = snpe->getInputDimensions();
-    size_t batchSize = tensorShape.getDimensions()[0];
-#ifdef ENABLE_GL_BUFFER
-    size_t bufSize = 0;
-    if (userBufferSourceType == GLBUFFER) {
-        if(batchSize > 1) {
-            std::cerr << "GL buffer source mode does not support batchsize larger than 1" << std::endl;
-            return EXIT_FAILURE;
-        }
-        bufSize = calcSizeFromDims(tensorShape.getDimensions(), tensorShape.rank(), sizeof(float));
-    }
-#endif
-    std::cout << "Batch size for the container is " << batchSize << std::endl;
+    // Bind the socket to a TCP address
+    std::string serverAddress = "tcp://*:5555";  // Replace with your desired address
+    socket.bind(serverAddress.c_str());
+	
 
-    // Open the input file listing and group input files into batches
-    std::vector<std::vector<std::string>> inputs = preprocessInput(inputFile, batchSize);
+    enum {UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16};
+    enum {CPUBUFFER, GLBUFFER};
 
-    // Load contents of input file batches ino a SNPE tensor or user buffer,
-    // user buffer include cpu buffer and OpenGL buffer,
-    // execute the network with the input and save each of the returned output to a file.
-    if(useUserSuppliedBuffers)
-    {
-       // SNPE allows its input and output buffers that are fed to the network
-       // to come from user-backed buffers. First, SNPE buffers are created from
-       // user-backed storage. These SNPE buffers are then supplied to the network
-       // and the results are stored in user-backed output buffers. This allows for
-       // reusing the same buffers for multiple inputs and outputs.
-       zdl::DlSystem::UserBufferMap inputMap, outputMap;
-       std::vector <std::unique_ptr<zdl::DlSystem::IUserBuffer>> snpeUserBackedInputBuffers, snpeUserBackedOutputBuffers;
-       std::unordered_map <std::string, std::vector<uint8_t>> applicationOutputBuffers;
-
-       if( bufferType == USERBUFFER_TF8 || bufferType == USERBUFFER_TF16 )
-       {
-          createOutputBufferMap(outputMap, applicationOutputBuffers, snpeUserBackedOutputBuffers, snpe, true, bitWidth);
-
-          std::unordered_map <std::string, std::vector<uint8_t>> applicationInputBuffers;
-          createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe, true, staticQuantization, bitWidth);
-
-          for( size_t i = 0; i < inputs.size(); i++ )
-          {
-             // Load input user buffer(s) with values from file(s)
-             if( batchSize > 1 )
-                std::cout << "Batch " << i << ":" << std::endl;
-             if(!loadInputUserBufferTfN(applicationInputBuffers, snpe, inputs[i], inputMap, staticQuantization, bitWidth))
-             {
-                 return EXIT_FAILURE;
-             }
-             // Execute the input buffer map on the model with SNPE
-             execStatus = snpe->execute(inputMap, outputMap);
-             // Save the execution results only if successful
-             if (execStatus == true)
-             {
-                if(!saveOutput(outputMap, applicationOutputBuffers, OutputDir, i * batchSize, batchSize, true, bitWidth))
-                {
-                    return EXIT_FAILURE;
-                }
-
-             }
-             else
-             {
-                std::cerr << "Error while executing the network." << std::endl;
-             }
-          }
-       }
-       else if( bufferType == USERBUFFER_FLOAT )
-       {
-          createOutputBufferMap(outputMap, applicationOutputBuffers, snpeUserBackedOutputBuffers, snpe, false, bitWidth);
-
-          if( userBufferSourceType == CPUBUFFER )
-          {
-             std::unordered_map <std::string, std::vector<uint8_t>> applicationInputBuffers;
-             createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe, false, false, bitWidth);
-
-             for( size_t i = 0; i < inputs.size(); i++ )
-             {
-                // Load input user buffer(s) with values from file(s)
-                if( batchSize > 1 )
-                   std::cout << "Batch " << i << ":" << std::endl;
-                if(!loadInputUserBufferFloat(applicationInputBuffers, snpe, inputs[i]))
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the input buffer map on the model with SNPE
-                execStatus = snpe->execute(inputMap, outputMap);
-                // Save the execution results only if successful
-                if (execStatus == true)
-                {
-                   if(!saveOutput(outputMap, applicationOutputBuffers, OutputDir, i * batchSize, batchSize, false, bitWidth))
-                   {
-                       return EXIT_FAILURE;
-                   }
-                }
-                else
-                {
-                   std::cerr << "Error while executing the network." << std::endl;
-                }
-             }
-          }
-#ifdef ENABLE_GL_BUFFER
-            if(userBufferSourceType  == GLBUFFER) {
-                std::unordered_map<std::string, GLuint> applicationInputBuffers;
-                createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe);
-                GLuint glBuffers = 0;
-                for(size_t i = 0; i < inputs.size(); i++) {
-                    // Load input GL buffer(s) with values from file(s)
-                    glBuffers = glBuffer->convertImage2GLBuffer(inputs[i], bufSize);
-                    loadInputUserBuffer(applicationInputBuffers, snpe, glBuffers);
-                    // Execute the input buffer map on the model with SNPE
-                    execStatus =  snpe->execute(inputMap, outputMap);
-                    // Save the execution results only if successful
-                    if (execStatus == true) {
-                        if(!saveOutput(outputMap, applicationOutputBuffers, OutputDir, i*batchSize, batchSize, false, bitWidth))
-                        {
-                            return EXIT_FAILURE;
-                        }
-                    }
-                    else
-                    {
-                        std::cerr << "Error while executing the network." << std::endl;
-                    }
-                    // Release the GL buffer(s)
-                    glDeleteBuffers(1, &glBuffers);
-                }
-            }
-#endif
-       }
-    }
-    else if(bufferType == ITENSOR)
-    {
-        // A tensor map for SNPE execution outputs
-        zdl::DlSystem::TensorMap outputTensorMap;
-        //Get input names and number
-        const auto& inputTensorNamesRef = snpe->getInputTensorNames();
-        if (!inputTensorNamesRef) throw std::runtime_error("Error obtaining Input tensor names");
-        const auto &inputTensorNames = *inputTensorNamesRef;
-
-        for (size_t i = 0; i < inputs.size(); i++) {
-            // Load input/output buffers with ITensor
-            if(batchSize > 1)
-                std::cout << "Batch " << i << ":" << std::endl;
-            if (inputTensorNames.size() == 1)
-            {
-                // Load input/output buffers with ITensor
-                std::unique_ptr<zdl::DlSystem::ITensor> inputTensor = loadInputTensor(snpe, inputs[i], inputTensorNames);
-                if(!inputTensor)
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the input tensor on the model with SNPE
-                execStatus = snpe->execute(inputTensor.get(), outputTensorMap);
-            }
-            else
-            {
-                std::vector<std::unique_ptr<zdl::DlSystem::ITensor>> inputTensors(inputTensorNames.size());
-                zdl::DlSystem::TensorMap inputTensorMap;
-                bool inputLoadStatus = false;
-                // Load input/output buffers with TensorMap
-                std::tie(inputTensorMap, inputLoadStatus) = loadMultipleInput(snpe, inputs[i], inputTensorNames, inputTensors);
-                if(!inputLoadStatus)
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the multiple input tensorMap on the model with SNPE
-                execStatus = snpe->execute(inputTensorMap, outputTensorMap);
-            }
-            // Save the execution results if execution successful
-            if (execStatus == true)
-            {
-               if(!saveOutput(outputTensorMap, OutputDir, i * batchSize, batchSize))
-               {
-                   return EXIT_FAILURE;
-               }
-            }
-            else
-            {
-               std::cerr << "Error while executing the network." << std::endl;
-            }
-        }
-    }
-    // Freeing of snpe object
+    std::unique_ptr<zdl::SNPE::SNPE> snpe;
 
-    // Terminate Logging
-    zdl::SNPE::SNPEFactory::terminateLogging();
+	zmq::message_t first_msg;  //TODO: 5 is hardcoded
+	zmq::message_t infer_time_reply;
+	
+	while(true)
+	{	
+		//Waiting for first msg from client;
+		std::cout << "\nWaiting for first msg from socket:";
+		socket.recv(&first_msg);
+		std::string receivedData_function = first_msg.to_string();
+		std::cout<<receivedData_function;
+
+		if(strcmp(receivedData_function.c_str(), "networkbuild") == 0)
+		{
+			//build network
+			std::cout<<"\nBUILDING NETWORK";
+			//Read other required parameters;
+			zmq::message_t msg1;
+			zmq::message_t msg2;
+			
+			socket.recv(&msg1);
+			std::string dlc = msg1.to_string();  //dlc_name_socket;
+			std::cout<<"\nreceived dlc name is: "<<dlc<<std::endl;
+			
+			socket.recv(&msg2);
+			std::string runtime_socket = msg2.to_string();
+			zdl::DlSystem::RuntimeList::stringToRuntime(runtime_socket.c_str());
+			std::cout<<"\nreceived runtime: "<<runtime_socket;
+			
+			
+			std::string bufferTypeStr = "USERBUFFER_FLOAT";
+			std::string userBufferSourceStr = "CPUBUFFER";
+			std::string staticQuantizationStr = "false";
+			static zdl::DlSystem::Runtime_t runtime;
+			
+			bool runtimeSpecified = true;
+			bool usingInitCaching = false;
+			
+			if (runtime_socket.compare("GPU") == 0)
+			{
+				runtime = zdl::DlSystem::Runtime_t::GPU;
+			}
+			else if (runtime_socket.compare("DSP") == 0)
+			{
+				runtime = zdl::DlSystem::Runtime_t::DSP;
+			}
+			else if (runtime_socket.compare("CPU") == 0)
+			{
+				runtime = zdl::DlSystem::Runtime_t::CPU;
+			}
+			else
+			{
+				std::cerr<<"\nCorrect Runtime not specified, choosing default(CPU)";
+				runtime = zdl::DlSystem::Runtime_t::CPU;
+			}
+
+			snpe = build_network(dlc, runtime, runtimeSpecified, usingInitCaching, bufferTypeStr, userBufferSourceStr, staticQuantizationStr);
+			if (snpe == nullptr)
+			{
+			   std::cerr << "Error while building SNPE object." << std::endl;
+			   return EXIT_FAILURE;
+			}
+			else
+			{
+				std::string build_success_str = "build is successful";
+				zmq::message_t message(build_success_str.size());
+				memcpy(message.data(), build_success_str.c_str(), build_success_str.size());
+				
+				socket.send(message);
+			}
+			
+		}
+		else if(strcmp(receivedData_function.c_str(), "infer") == 0)
+		{
+			//make inference
+			bool execStatus = false;
+
+			if (snpe == nullptr)
+			{
+				std::cerr << "Error while building SNPE object." << std::endl;
+				return EXIT_FAILURE;
+			}
+
+			std::cout << "\nMAKING INFERENCE";
+
+			useUserSuppliedBuffers = true; //TODO: hardcoded but take it from builder functions
+
+
+			// Check the batch size for the container
+			// SNPE 1.16.0 (and newer) assumes the first dimension of the tensor shape
+			// is the batch size.
+			zdl::DlSystem::TensorShape tensorShape;
+			tensorShape = snpe->getInputDimensions();
+			size_t batchSize = tensorShape.getDimensions()[0];
+			std::cout << "Batch size for the container is " << batchSize << std::endl;
+
+			try {
+				zmq::message_t messages;
+				socket.recv(&messages);
+
+				std::vector<float> receivedData(static_cast<float*>(messages.data()), static_cast<float*>(messages.data()) + messages.size() / sizeof(float));
+
+				if (useUserSuppliedBuffers)
+				{
+					// SNPE allows its input and output buffers that are fed to the network
+					// to come from user-backed buffers. First, SNPE buffers are created from
+					// user-backed storage. These SNPE buffers are then supplied to the network
+					// and the results are stored in user-backed output buffers. This allows for
+					// reusing the same buffers for multiple inputs and outputs.
+
+					zdl::DlSystem::UserBufferMap inputMap, outputMap;
+					std::vector <std::unique_ptr<zdl::DlSystem::IUserBuffer>> snpeUserBackedInputBuffers, snpeUserBackedOutputBuffers;
+					std::unordered_map <std::string, std::vector<float>> applicationOutputBuffersFloat;
+
+					if (bufferType == USERBUFFER_FLOAT)
+					{
+						std::cout << "userbuffer float" << std::endl;
+						createOutputBufferMap(outputMap, applicationOutputBuffersFloat, snpeUserBackedOutputBuffers, snpe, false, bitWidth);
+						std::cout << "createOutputBufferMap done" << std::endl;
+						
+						std::unordered_map <std::string, std::vector<float>> applicationInputBuffersFloat;
+
+						createInputBufferMap(inputMap, applicationInputBuffersFloat, snpeUserBackedInputBuffers, snpe, false, false, bitWidth);
+						
+						const auto& outputNamesOpt = snpe->getOutputTensorNames();
+						const zdl::DlSystem::StringList& outputNames = *outputNamesOpt;
+						const char* out_name = outputNames.at(0);  //Only one output is present
+						
+						const auto& inputNamesOpt = snpe->getInputTensorNames();
+						const zdl::DlSystem::StringList& inputNames = *inputNamesOpt;
+						const char* in_name = inputNames.at(0);  //Only one input is present
+	
+						applicationInputBuffersFloat.at(in_name) = receivedData;
+						for (size_t i = 0; i < batchSize; i++)
+						{
+							// Load input user buffer(s) with values from file(s)
+							if (batchSize > 1)
+								std::cout << "Batch " << i << ":" << std::endl;
+
+							uint64_t start_ms = std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count();
+						   
+							// Execute the input buffer map on the model with SNPE
+							execStatus = snpe->execute(inputMap, outputMap);
+							std::cout << "\nExecStatus: " << execStatus;
+
+							uint64_t end_ms = std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count();
+
+							int infer_time = end_ms - start_ms;
+
+							std::string mill_str = std::to_string(infer_time);
+							std::cout<<"Inference time:"<<mill_str;
+							infer_time_reply.rebuild(mill_str.size());
+							memcpy((void *) infer_time_reply.data(), (mill_str.c_str()), mill_str.size());
+							
+							// Prepare the vectors(execution result) to be sent
+							std::vector<float> vector = applicationOutputBuffersFloat.at(out_name);
+
+							// Send the result
+							if (execStatus == true)
+							{
+								std::cout << "execStatus is true";
+								zmq::message_t message(vector.size());
+								std::cout << "\nCopying msg";
+
+								std::cout << "\nvector size: " << vector.size();
+								std::memcpy(message.data(), vector.data(), vector.size());
+								socket.send(message);
+								std::cout << "\nimage sent";
+							}
+							else
+							{
+								std::cerr << "Error while executing the network." << std::endl;
+							}
+						}
+					}
+				}
+			}
+			catch (std::exception& e){
+				std::cout << "ERROR: e: " << e.what();
+			}
+		}
+		else if (strcmp(receivedData_function.c_str(),"get_infer_time")==0)
+		{
+			std::cout<<"sending infertime:";
+			socket.send(infer_time_reply);
+			std::cout << "message sent out" << std::endl;
+		}
+		else
+		{
+			std::cerr << "Fist msg do not match";
+		}
+	}
 
+    // Freeing of snpe object
     snpe.reset();
     return SUCCESS;
 }
+
