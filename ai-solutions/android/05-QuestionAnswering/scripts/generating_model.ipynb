{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416d10e9-51d0-45da-b016-970e1db53d26",
   "metadata": {},
   "source": [
    "# Preparaing the dataset\n",
    "- [ https://rajpurkar.github.io/SQuAD-explorer/ ] (Dataset link)\n",
    "- Download the dataset from the above link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807742c0-4c3b-4a8c-af79-04fb2f5fdf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-09-30 21:58:42--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4370528 (4.2M) [application/json]\n",
      "Saving to: ‘dev-v2.0.json’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  719K 6s\n",
      "    50K .......... .......... .......... .......... ..........  2%  900K 5s\n",
      "   100K .......... .......... .......... .......... ..........  3% 3.85M 4s\n",
      "   150K .......... .......... .......... .......... ..........  4% 1.35M 4s\n",
      "   200K .......... .......... .......... .......... ..........  5% 4.65M 3s\n",
      "   250K .......... .......... .......... .......... ..........  7% 5.76M 3s\n",
      "   300K .......... .......... .......... .......... ..........  8% 7.24M 2s\n",
      "   350K .......... .......... .......... .......... ..........  9% 7.54M 2s\n",
      "   400K .......... .......... .......... .......... .......... 10% 1.76M 2s\n",
      "   450K .......... .......... .......... .......... .......... 11% 10.2M 2s\n",
      "   500K .......... .......... .......... .......... .......... 12% 10.1M 2s\n",
      "   550K .......... .......... .......... .......... .......... 14% 11.2M 2s\n",
      "   600K .......... .......... .......... .......... .......... 15% 11.4M 1s\n",
      "   650K .......... .......... .......... .......... .......... 16% 10.7M 1s\n",
      "   700K .......... .......... .......... .......... .......... 17% 13.0M 1s\n",
      "   750K .......... .......... .......... .......... .......... 18% 13.4M 1s\n",
      "   800K .......... .......... .......... .......... .......... 19% 14.5M 1s\n",
      "   850K .......... .......... .......... .......... .......... 21% 2.22M 1s\n",
      "   900K .......... .......... .......... .......... .......... 22% 19.1M 1s\n",
      "   950K .......... .......... .......... .......... .......... 23% 17.1M 1s\n",
      "  1000K .......... .......... .......... .......... .......... 24% 21.7M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 25% 13.6M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 26% 24.9M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 28% 24.1M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 29% 28.2M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 30% 17.8M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 31% 27.6M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 32% 22.9M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 33% 19.8M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 35% 35.0M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 36% 25.5M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 37% 20.9M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 38% 35.2M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 39% 46.7M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 41% 24.1M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 42% 31.5M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 43% 2.35M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 44% 35.3M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 45% 41.5M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 46% 25.7M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 48% 61.4M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 49% 28.5M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 50% 30.0M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 51% 68.0M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 52% 28.7M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 53% 52.5M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 55% 30.4M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 56% 35.7M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 57% 70.5M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 58% 39.8M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 59% 48.3M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 60% 45.0M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 62% 49.3M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 63% 39.7M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 64% 48.1M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 65% 37.5M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 66% 47.9M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 67%  116M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 69% 49.7M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 70% 35.5M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 71% 75.1M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 72% 59.2M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 73% 46.0M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 74% 61.9M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 76% 39.6M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 77% 75.0M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 78% 81.7M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 79% 47.1M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 80% 58.4M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 82% 55.1M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 83% 77.9M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 84% 76.7M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 85% 53.3M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 86% 2.49M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 87% 42.9M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 89%  151M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 90% 85.8M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 91% 70.3M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 92% 54.2M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 93% 45.9M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 94%  181M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 96% 77.4M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 97% 55.5M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 98% 64.1M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 99% 68.7M 0s\n",
      "  4250K .......... ........                                   100%  226M=0.4s\n",
      "\n",
      "2023-09-30 21:58:43 (10.1 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cbcc78-e8ba-43c2-b351-f86695041835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                                        question                      answers  \n",
       "0           In what country is Normandy located?                       France  \n",
       "1             When were the Normans in Normandy?      10th and 11th centuries  \n",
       "2  From which countries did the Norse originate?  Denmark, Iceland and Norway  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_path=\"dev-v2.0.json\"\n",
    "\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "\n",
    "context_qa_triples=[]\n",
    "\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a9faed-f7ac-4f45-a557-d5adc8762dca",
   "metadata": {},
   "source": [
    "# Generating Albert Model\n",
    "- [Albert Model](https://huggingface.co/docs/transformers/model_doc/albert) You can Learn More about this model from this link\n",
    "- You can also check different version of Albert for different usecases from here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83206f-1109-4b87-aea2-11bfede84967",
   "metadata": {},
   "source": [
    "### Converting the Model to ONNX format using optimum\n",
    "- [ https://github.com/huggingface/optimum ] (Link for optimum)\n",
    "- Using optimum we can directly convert any pytorch or tensorflow model to onnx format.\n",
    "- Then from this onnx file we can convert to DLC format using SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83500540-ebc7-45aa-a675-ea863f1db3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:10.386023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 21:59:10.461126: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 21:59:10.479101: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-30 21:59:10.790954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:10.790993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:10.790997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "Some weights of the model checkpoint at twmkn9/albert-base-v2-squad2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.weight', 'albert.pooler.bias']\n",
      "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Automatic task detection to question-answering.\n",
      "Using framework PyTorch: 2.0.1+cu117\n",
      "Post-processing the exported models...\n",
      "Validating models in subprocesses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:16.200782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 21:59:16.275655: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 21:59:16.293026: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-30 21:59:16.602860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:16.602899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:16.602903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Validating ONNX model alberta-onnx/model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (start_logits, end_logits)\n",
      "\t- Validating ONNX Model output \"start_logits\":\n",
      "\t\t-[✓] (2, 16) matches (2, 16)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"end_logits\":\n",
      "\t\t-[✓] (2, 16) matches (2, 16)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "The ONNX export succeeded and the exported model was saved at: alberta-onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "optimum-cli export onnx --model twmkn9/albert-base-v2-squad2 alberta-onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23e961-0113-4ee6-87d9-6391f9105fe2",
   "metadata": {},
   "source": [
    "### DLC Conversion with fixed size\n",
    "- Now as we get the ONNX Model we'll now convert this to DLC Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f98873c-afd1-4ba0-b3c2-1f28a5e0b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mWARNING: The argument `input_shapes` is deprecated. Please use \u001b[0m\n",
      "\u001b[1;31m`overwrite_input_shapes` and/or `test_input_shapes` instead. An error will be \u001b[0m\n",
      "\u001b[1;31mraised in the future.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:25,991 - 235 - INFO - Successfully simplified the onnx model in child process\n",
      "2023-09-30 21:59:26,137 - 235 - INFO - Successfully receive the simplified onnx model in main process\n",
      "2023-09-30 21:59:26,209 - 235 - INFO - Successfully run shape inference in child process\n",
      "2023-09-30 21:59:26,365 - 235 - INFO - Successfully receive the inferred model in main process\n",
      "2023-09-30 21:59:26,396 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /albert/Cast will be interpreted at conversion time\n",
      "2023-09-30 21:59:28,072 - 235 - INFO - INFO_INITIALIZATION_SUCCESS: \n",
      "2023-09-30 21:59:28,234 - 235 - INFO - INFO_CONVERSION_SUCCESS: Conversion completed successfully\n",
      "2023-09-30 21:59:28,289 - 235 - INFO - INFO_WRITE_SUCCESS: \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snpe-onnx-to-dlc -i alberta-onnx/model.onnx -d input_ids 1,384 -d attention_mask 1,384 -d token_type_ids 1,384 -o alberta.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c0356-9a15-4ef1-9f63-3f1baf41eed7",
   "metadata": {},
   "source": [
    "### Creating FP16 Model\n",
    "1. First of all we need to create the RAW File\n",
    "2. Then we'll convert this FP32 DLC to FP16 DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0710645-b945-486f-9050-945e1058faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir input_ids\n",
    "mkdir attention_mask\n",
    "mkdir token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe8f2a-e140-4828-ba36-5171fbba9b6e",
   "metadata": {},
   "source": [
    "#### Creating the RAW Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a27bfe7-d501-4b57-9b55-a3e3374e2dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:29.221362: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 21:59:29.295276: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 21:59:29.313236: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-30 21:59:29.610631: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:29.610673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:29.610677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Getting the tokenizer to convert it to particular inputs that the model needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "\n",
    "question_token={}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31780ce6-882d-48dc-b589-e893e429d9fd",
   "metadata": {},
   "source": [
    "#### Creating the List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca58728-3401-4653-8542-b823f735264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating input_list \"small_raw_list.txt\" with 30 iterations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_iter = 30\n",
    "print(\"Generating input_list \\\"small_raw_list.txt\\\" with {} iterations\".format(total_iter))\n",
    "\n",
    "with open(\"tf_raw_list.txt\",'w') as f:\n",
    "    for i in range(total_iter):\n",
    "        f.write(\"input_ids:=input_ids/inp_ids_{}.raw attention_mask:=attention_mask/attn_mask_{}.raw token_type_ids:=token_type_ids/token_type_id_{}.raw\\n\".format(i,i,i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4ca35-caf7-4ffa-a954-bc8405386276",
   "metadata": {},
   "source": [
    "### Creating the FP16 Model\n",
    "- This cached model is optimized for sm8550\n",
    "- if you've different processor please change it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c82fc7-3b70-4898-be64-0ad9d0dd0312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] SNPE HTP Offline Prepare: Attempting to create cache for SM8550\n",
      "[INFO] Attempting to open dynamically linked lib: libHtpPrepare.so\n",
      "[INFO] dlopen libHtpPrepare.so SUCCESS handle 0x18363b0\n",
      "[INFO] Found Interface Provider (v2.8)\n",
      "[USER_WARNING] QnnDsp <W> Initializing HtpProvider\n",
      "[USER_WARNING] QnnDsp <W> Cost Based unsupported on soc SM8550\n",
      "[USER_INFO] FP16 precision enabled for graph with id=0\n",
      "[USER_INFO] Offline Prepare VTCM size(MB) selected = 8\n",
      "[USER_INFO] Offline Prepare DLBC enablement passed = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[USER_INFO] Cleaning up backend manager resources\n",
      "[USER_INFO] Cleaning up Contexts\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] SNPE HTP Offline Prepare: Successfully created cache for SM8550\n",
      "[INFO] SNPE HTP Offline Prepare: Saved cached DLC to alberta_float.dlc\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "snpe-dlc-graph-prepare --input_dlc alberta.dlc --input_list tf_raw_list.txt  --output_dlc alberta_float.dlc --set_output_tensors end_logits,start_logits --use_float_io --htp_socs sm8550"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd975495-2aef-4f3d-87be-9370bbf605da",
   "metadata": {},
   "source": [
    "# Generating Mobilebert Model\n",
    "- [Mobile bert ](https://huggingface.co/csarron/mobilebert-uncased-squad-v2/tree/main) You can Learn More about this model from this link\n",
    "- To check more about different use cases of Mobilebert you can use this [link](https://huggingface.co/docs/transformers/model_doc/mobilebert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfc9e5-4134-4656-94fb-f3641848818f",
   "metadata": {},
   "source": [
    "### Generating the ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650cebf7-1697-4a9d-bb53-4903a7b304b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:36.311479: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 21:59:36.385244: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 21:59:36.402226: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-30 21:59:36.706875: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:36.706914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:36.706918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "Automatic task detection to question-answering.\n",
      "Using framework PyTorch: 2.0.1+cu117\n",
      "/local/mnt/workspace/sahinhos/sahinenv/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:549: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(1000),\n",
      "/local/mnt/workspace/sahinhos/sahinenv/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/local/mnt/workspace/sahinhos/sahinenv/lib/python3.8/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/local/mnt/workspace/sahinhos/sahinenv/lib/python3.8/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "Post-processing the exported models...\n",
      "Validating models in subprocesses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:59:51.377048: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 21:59:51.452021: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 21:59:51.469676: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-30 21:59:51.779129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:51.779165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/snpe-2.14.0.230828/lib/x86_64-linux-clang\n",
      "2023-09-30 21:59:51.779169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Validating ONNX model mobilebert-onnx/model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (end_logits, start_logits)\n",
      "\t- Validating ONNX Model output \"start_logits\":\n",
      "\t\t-[✓] (2, 16) matches (2, 16)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"end_logits\":\n",
      "\t\t-[✓] (2, 16) matches (2, 16)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "The ONNX export succeeded and the exported model was saved at: mobilebert-onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "optimum-cli export onnx --model csarron/mobilebert-uncased-squad-v2 mobilebert-onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6f6ef-1088-4ac2-b4fe-8aeceaa5d42a",
   "metadata": {},
   "source": [
    "### Converting to DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219fc000-a9bb-483e-891e-2e9db570ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1;31mWARNING: The argument `input_shapes` is deprecated. Please use \u001b[0m\n",
      "\u001b[1;31m`overwrite_input_shapes` and/or `test_input_shapes` instead. An error will be \u001b[0m\n",
      "\u001b[1;31mraised in the future.\u001b[0m\n",
      "WARNING: the simplification stopped because of timeout. Please set environment variable `ONNXSIM_FIXED_POINT_ITERS` to a number higher than 50if you want further simplification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 22:00:38,259 - 235 - INFO - Successfully simplified the onnx model in child process\n",
      "2023-09-30 22:00:38,608 - 235 - INFO - Successfully receive the simplified onnx model in main process\n",
      "2023-09-30 22:00:38,756 - 235 - INFO - Successfully run shape inference in child process\n",
      "2023-09-30 22:00:39,093 - 235 - INFO - Successfully receive the inferred model in main process\n",
      "2023-09-30 22:00:39,127 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /mobilebert/Cast will be interpreted at conversion time\n",
      "2023-09-30 22:00:45,555 - 235 - INFO - INFO_INITIALIZATION_SUCCESS: \n",
      "2023-09-30 22:00:46,066 - 235 - INFO - INFO_CONVERSION_SUCCESS: Conversion completed successfully\n",
      "2023-09-30 22:00:46,188 - 235 - INFO - INFO_WRITE_SUCCESS: \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snpe-onnx-to-dlc -i mobilebert-onnx/model.onnx -d input_ids 1,384 -d attention_mask 1,384 -d token_type_ids 1,384 -o mobile_bert.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c34ca-0e44-4e4f-9fed-d67da3e83a3b",
   "metadata": {},
   "source": [
    "### Creating the RAW file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aca1352-6a30-4614-9734-f3930774f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, MobileBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"csarron/mobilebert-uncased-squad-v2\")\n",
    "\n",
    "\n",
    "question_token={}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf159fd3-32b9-4416-ad89-6fe1b3516ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating input_list \"small_raw_list.txt\" with 30 iterations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_iter = 30\n",
    "print(\"Generating input_list \\\"small_raw_list.txt\\\" with {} iterations\".format(total_iter))\n",
    "\n",
    "with open(\"tf_raw_list.txt\",'w') as f:\n",
    "    for i in range(total_iter):\n",
    "        f.write(\"input_ids:=input_ids/inp_ids_{}.raw attention_mask:=attention_mask/attn_mask_{}.raw token_type_ids:=token_type_ids/token_type_id_{}.raw\\n\".format(i,i,i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7c71a-ac10-4a31-bcc2-3ddba9dc0a86",
   "metadata": {},
   "source": [
    "#### Creating the FP 16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f2d588-01e0-4a0e-88d8-7b4823e89143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] SNPE HTP Offline Prepare: Attempting to create cache for SM8550\n",
      "[INFO] Attempting to open dynamically linked lib: libHtpPrepare.so\n",
      "[INFO] dlopen libHtpPrepare.so SUCCESS handle 0x17b9a90\n",
      "[INFO] Found Interface Provider (v2.8)\n",
      "[USER_WARNING] QnnDsp <W> Initializing HtpProvider\n",
      "[USER_WARNING] QnnDsp <W> Cost Based unsupported on soc SM8550\n",
      "[USER_INFO] FP16 precision enabled for graph with id=0\n",
      "[USER_INFO] Offline Prepare VTCM size(MB) selected = 8\n",
      "[USER_INFO] Offline Prepare DLBC enablement passed = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[USER_INFO] Cleaning up backend manager resources\n",
      "[USER_INFO] Cleaning up Contexts\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] SNPE HTP Offline Prepare: Successfully created cache for SM8550\n",
      "[INFO] SNPE HTP Offline Prepare: Saved cached DLC to mobile_bert_float.dlc\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snpe-dlc-graph-prepare --input_dlc mobile_bert.dlc --input_list tf_raw_list.txt  --output_dlc mobile_bert_float.dlc --use_float_io --set_output_tensors end_logits,start_logits --htp_socs sm8550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c159f63-d842-481f-9f41-ebf34c522cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366aff04-6160-4f85-b0ea-711132fdc06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4b107-1a84-41d9-9301-b42b094f4e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
