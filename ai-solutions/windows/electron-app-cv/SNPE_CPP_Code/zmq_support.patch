diff --git a/CMakeLists.txt b/CMakeLists.txt
index f4686c3..e39b176 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -14,6 +14,8 @@ set (APP "snpe-sample")
 option(BUILD_WITH_VCRUNTIME "Build the snpe-sample with static vcruntime libraries." OFF)
 message("Build snpe-sample with vcruntime: ${BUILD_WITH_VCRUNTIME}")
 
+message("CHIPSET= ${CHIPSET}")
+
 set( APP_SOURCES
     "main.cpp"
     "Util.cpp"
@@ -38,8 +40,9 @@ set( APP_SOURCES
     "CreateUserBuffer.hpp"
 )
 
-set (SNPE_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../../../../include/SNPE)
-set (SNPE_LIB_PREFIX ../../../../lib)
+set (SNPE_INCLUDE_DIR "C:/Qualcomm/AIStack/SNPE/2.14.1.230828/include/SNPE")
+set (SNPE_LIB_PREFIX "C:/Qualcomm/AIStack/SNPE/2.14.1.230828/lib")
+set (ZERO_MQ_PATH "C:/Program Files (x86)/ZeroMQ")
 set (_dtuple_POSTFIX windows-msvc)
 
 if(CMAKE_GENERATOR_PLATFORM STREQUAL "x64")
@@ -48,8 +51,20 @@ if(CMAKE_GENERATOR_PLATFORM STREQUAL "x64")
     get_filename_component(SNPE_IMPLIB_PATH "${SNPE_LIB_PREFIX}/x86_64-${_dtuple_POSTFIX}/SNPE.lib" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
 elseif(CMAKE_GENERATOR_PLATFORM STREQUAL "ARM64")
     message("Linking with ARM64 SNPE")
-    get_filename_component(SNPE_DLL_PATH "${SNPE_LIB_PREFIX}/aarch64-${_dtuple_POSTFIX}/SNPE.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
-    get_filename_component(SNPE_IMPLIB_PATH "${SNPE_LIB_PREFIX}/aarch64-${_dtuple_POSTFIX}/SNPE.lib" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+    get_filename_component(SNPE_DLL_PATH "${SNPE_LIB_PREFIX}/arm64x-${_dtuple_POSTFIX}/SNPE.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+    get_filename_component(SNPE_IMPLIB_PATH "${SNPE_LIB_PREFIX}/arm64x-${_dtuple_POSTFIX}/SNPE.lib" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+   	get_filename_component(ZMQ_DLL_PATH "${ZERO_MQ_PATH}/bin/libzmq-v143-mt-gd-4_3_6.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+	get_filename_component(SNPE_HTP_PATH "${SNPE_LIB_PREFIX}/arm64x-${_dtuple_POSTFIX}/SnpeHtpPrepare.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+	
+	if(CHIPSET STREQUAL "SC8380")
+		message("SC8380 is selected")
+		get_filename_component(SNPE_STUB_PATH "${SNPE_LIB_PREFIX}/arm64x-${_dtuple_POSTFIX}/SnpeHtpV73Stub.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+		get_filename_component(SNPE_SKEL_PATH "${SNPE_LIB_PREFIX}/hexagon-v73/unsigned/libSnpeHtpV73Skel.so" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+	else()
+		message("Default is selected")
+		get_filename_component(SNPE_STUB_PATH "${SNPE_LIB_PREFIX}/arm64x-${_dtuple_POSTFIX}/SnpeHtpV68Stub.dll" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+		get_filename_component(SNPE_SKEL_PATH "${SNPE_LIB_PREFIX}/hexagon-v68/unsigned/libSnpeHtpV68Skel.so" REALPATH BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
+	endif()
 else()
     message(FATAL "Not Supported Platform")
 endif()
@@ -61,13 +76,33 @@ set_target_properties(SNPE PROPERTIES
     INTERFACE_INCLUDE_DIRECTORIES ${SNPE_INCLUDE_DIR}
 )
 
+find_package(cppzmq)
 add_executable(${APP} ${APP_SOURCES})
 target_compile_definitions(${APP} PUBLIC -D_CRT_SECURE_NO_WARNINGS)
 if(${BUILD_WITH_VCRUNTIME})
     target_compile_options(${APP} PUBLIC /MT)
 endif()
-target_link_libraries (${APP} SNPE)
+target_link_libraries (${APP} SNPE cppzmq)
 add_custom_command(TARGET ${APP} POST_BUILD
     COMMAND ${CMAKE_COMMAND} -E copy_if_different
     ${SNPE_DLL_PATH}
     $<TARGET_FILE_DIR:${APP}>)
+
+add_custom_command(TARGET ${APP} POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy_if_different
+    ${SNPE_STUB_PATH}
+    $<TARGET_FILE_DIR:${APP}>)
+
+add_custom_command(TARGET ${APP} POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy_if_different
+    ${SNPE_HTP_PATH}
+    $<TARGET_FILE_DIR:${APP}>)
+
+add_custom_command(TARGET ${APP} POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy_if_different
+    ${SNPE_SKEL_PATH}
+    $<TARGET_FILE_DIR:${APP}>)
+add_custom_command(TARGET ${APP} POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy_if_different
+    ${ZMQ_DLL_PATH}
+    $<TARGET_FILE_DIR:${APP}>)
\ No newline at end of file
diff --git a/CreateUserBuffer.cpp b/CreateUserBuffer.cpp
index fa500e5..d2a5bbe 100644
--- a/CreateUserBuffer.cpp
+++ b/CreateUserBuffer.cpp
@@ -199,3 +199,131 @@ void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
       createUserBuffer(inputMap, applicationBuffers, snpeUserBackedBuffers, snpe, name);
    }
 }
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
+                      std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                      std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                      std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                      const char * name,
+                      const bool isTfNBuffer,
+                      bool staticQuantization,
+                      int bitWidth)
+{
+   // get attributes of buffer by name
+   auto bufferAttributesOpt = snpe->getInputOutputBufferAttributes(name);
+   if (!bufferAttributesOpt) throw std::runtime_error(std::string("Error obtaining attributes for input tensor ") + name);
+
+   // calculate the size of buffer required by the input tensor
+   const zdl::DlSystem::TensorShape& bufferShape = (*bufferAttributesOpt)->getDims();
+
+    size_t bufferElementSize = 0;
+    if (isTfNBuffer) {
+        bufferElementSize = bitWidth / 8;
+    }
+    else {
+        bufferElementSize = sizeof(float);
+    }
+
+   // Calculate the stride based on buffer strides.
+   // Note: Strides = Number of bytes to advance to the next element in each dimension.
+   // For example, if a float tensor of dimension 2x4x3 is tightly packed in a buffer of 96 bytes, then the strides would be (48,12,4)
+   // Note: Buffer stride is usually known and does not need to be calculated.
+   std::vector<size_t> strides(bufferShape.rank());
+   strides[strides.size() - 1] = bufferElementSize;
+   size_t stride = strides[strides.size() - 1];
+   for (size_t i = bufferShape.rank() - 1; i > 0; i--)
+   {
+      (bufferShape[i] == 0) ? stride *= getResizableDim() : stride *= bufferShape[i];
+      strides[i-1] = stride;
+   }
+
+   size_t bufSize = calcSizeFromDims(bufferShape.getDimensions(), bufferShape.rank(), bufferElementSize);
+
+   // set the buffer encoding type
+   std::unique_ptr<zdl::DlSystem::UserBufferEncoding> userBufferEncoding;
+   if (isTfNBuffer)
+   {
+      if((*bufferAttributesOpt)->getEncodingType() == zdl::DlSystem::UserBufferEncoding::ElementType_t::FLOAT && staticQuantization){
+         std::cerr << "ERROR: Quantization parameters not present in model" << std::endl;
+         std::exit(EXIT_FAILURE);
+      }
+
+      const zdl::DlSystem::UserBufferEncodingTfN* ubeTfN = dynamic_cast<const zdl::DlSystem::UserBufferEncodingTfN*>((*bufferAttributesOpt)->getEncoding());
+      uint64_t stepEquivalentTo0 = ubeTfN->getStepExactly0();
+      float quantizedStepSize = ubeTfN->getQuantizedStepSize();
+      userBufferEncoding = std::unique_ptr<zdl::DlSystem::UserBufferEncodingTfN>(new zdl::DlSystem::UserBufferEncodingTfN(stepEquivalentTo0,quantizedStepSize, bitWidth));
+   }
+   else
+   {
+      userBufferEncoding = std::unique_ptr<zdl::DlSystem::UserBufferEncodingFloat>(new zdl::DlSystem::UserBufferEncodingFloat());
+   }
+
+   // create user-backed storage to load input data onto it
+   applicationBuffers.emplace(name, std::vector<float>(bufSize));
+
+   // create SNPE user buffer from the user-backed buffer
+   zdl::DlSystem::IUserBufferFactory& ubFactory = zdl::SNPE::SNPEFactory::getUserBufferFactory();
+   snpeUserBackedBuffers.push_back(ubFactory.createUserBuffer(applicationBuffers.at(name).data(),
+                                                              bufSize,
+                                                              strides,
+                                                              userBufferEncoding.get()));
+   if (snpeUserBackedBuffers.back() == nullptr)
+   {
+      std::cerr << "Error while creating user buffer." << std::endl;
+   }
+   // add the user-backed buffer to the inputMap, which is later on fed to the network for execution
+   userBufferMap.add(name, snpeUserBackedBuffers.back().get());
+}
+
+void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
+                          std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                          std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                          std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                          bool isTfNBuffer,
+                          bool staticQuantization,
+                          int bitWidth)
+{
+   // get input tensor names of the network that need to be populated
+   const auto& inputNamesOpt = snpe->getInputTensorNames();
+   if (!inputNamesOpt) throw std::runtime_error("Error obtaining input tensor names");
+   const zdl::DlSystem::StringList& inputNames = *inputNamesOpt;
+   assert(inputNames.size() > 0);
+
+   // create SNPE user buffers for each application storage buffer
+   for (const char *name : inputNames) {
+      createUserBuffer(inputMap, applicationBuffers, snpeUserBackedBuffers, snpe, name, isTfNBuffer, staticQuantization, bitWidth);
+   }
+}
+
+void createOutputBufferMap(zdl::DlSystem::UserBufferMap& outputMap,
+                           std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                           std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                           std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                           bool isTfNBuffer,
+                           int bitWidth)
+{
+   // get input tensor names of the network that need to be populated
+   const auto& outputNamesOpt = snpe->getOutputTensorNames();
+   if (!outputNamesOpt) throw std::runtime_error("Error obtaining output tensor names");
+   const zdl::DlSystem::StringList& outputNames = *outputNamesOpt;
+
+   // create SNPE user buffers for each application storage buffer
+   for (const char *name : outputNames) {
+      createUserBuffer(outputMap, applicationBuffers, snpeUserBackedBuffers, snpe, name, isTfNBuffer, false, bitWidth);
+   }
+}
\ No newline at end of file
diff --git a/CreateUserBuffer.hpp b/CreateUserBuffer.hpp
index 138a7c4..4a6cf60 100644
--- a/CreateUserBuffer.hpp
+++ b/CreateUserBuffer.hpp
@@ -53,3 +53,33 @@ void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
                           std::unordered_map<std::string, GLuint>& applicationBuffers,
                           std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
                           std::unique_ptr<zdl::SNPE::SNPE>& snpe);
+
+
+
+
+
+void createUserBuffer(zdl::DlSystem::UserBufferMap& userBufferMap,
+                      std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                      std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                      std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                      const char * name,
+                      const bool isTfNBuffer,
+                      bool staticQuantization,
+                      int bitWidth);
+
+// Create a UserBufferMap of the SNPE network inputs
+void createInputBufferMap(zdl::DlSystem::UserBufferMap& inputMap,
+                          std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                          std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                          std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                          const bool isTfNBuffer,
+                          bool staticQuantization,
+                          int bitWidth);
+
+// Create a UserBufferMap of the SNPE network outputs
+void createOutputBufferMap(zdl::DlSystem::UserBufferMap& outputMap,
+                           std::unordered_map<std::string, std::vector<float>>& applicationBuffers,
+                           std::vector<std::unique_ptr<zdl::DlSystem::IUserBuffer>>& snpeUserBackedBuffers,
+                           std::unique_ptr<zdl::SNPE::SNPE>& snpe,
+                           const bool isTfNBuffer,
+                           int bitWidth);
diff --git a/SetBuilderOptions.cpp b/SetBuilderOptions.cpp
index 20bbeca..75284fb 100644
--- a/SetBuilderOptions.cpp
+++ b/SetBuilderOptions.cpp
@@ -36,6 +36,7 @@ std::unique_ptr<zdl::SNPE::SNPE> setBuilderOptions(std::unique_ptr<zdl::DlContai
        .setUseUserSuppliedBuffers(useUserSuppliedBuffers)
        .setPlatformConfig(platformConfig)
        .setInitCacheMode(useCaching)
+       .setUnconsumedTensorsAsOutputs(true)
        .build();
     return snpe;
 }
diff --git a/main.cpp b/main.cpp
index 729e03b..de52411 100644
--- a/main.cpp
+++ b/main.cpp
@@ -9,9 +9,10 @@
 // This file contains an example application that loads and executes a neural
 // network using the SNPE C++ API and saves the layer output to a file.
 // Inputs to and outputs from the network are conveyed in binary form as single
-// precision floating point values.
+// precision uint8_ting point values.
 //
 
+#define ZMQ_STATIC
 #include <iostream>
 #include <fstream>
 #include <cstdlib>
@@ -20,6 +21,10 @@
 #include <iterator>
 #include <unordered_map>
 #include <algorithm>
+#include <zmq.hpp>
+#include <zmq_addon.hpp>
+#include <chrono>
+#include <windows.h>
 
 #include "GetOpt.hpp"
 #include "CheckRuntime.hpp"
@@ -40,455 +45,419 @@
 /* Windows Modification
 * Replace <getopt.h> to <GetOpt.hpp> and refactor the "Process command line arguments" part
 */
-
 const int FAILURE = 1;
 const int SUCCESS = 0;
 
-int main(int argc, char** argv)
+enum { UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16 };
+enum { CPUBUFFER, GLBUFFER };
+bool useUserSuppliedBuffers = false;
+int bufferType;
+int bitWidth = 0;
+
+std::string getCurrentDir() {
+	char buff[MAX_PATH];
+	GetModuleFileName(NULL, buff, MAX_PATH);
+	std::string::size_type position = std::string(buff).find_last_of("\\/");
+	return std::string(buff).substr(0, position);
+}
+
+std::unique_ptr<zdl::SNPE::SNPE> build_network(std::string dlc, static zdl::DlSystem::Runtime_t runtime, bool runtimeSpecified, bool usingInitCaching, std::string bufferTypeStr, std::string userBufferSourceStr, std::string staticQuantizationStr)
+{
+
+	static zdl::DlSystem::RuntimeList runtimeList;
+	bool staticQuantization;
+
+	if (staticQuantizationStr == "true")
+	{
+		staticQuantization = true;
+	}
+	else if (staticQuantizationStr == "false")
+	{
+		staticQuantization = false;
+	}
+	else
+	{
+		std::cout << "\nStatic quantization value is not valid. Please run snpe-sample with the -h flag for more details"
+			<< std::endl;
+		return nullptr;
+	}
+
+	if (runtimeList.empty() == false)
+	{
+		std::cout << "runtimelist not empty" << std::endl;
+	}
+
+	if (runtimeSpecified)
+	{
+		std::cout << "runtime is specificed" << std::endl;
+	}
+
+	// Check if given arguments represent valid files
+	std::ifstream dlcFile(dlc);
+	if (!dlcFile) {
+		std::cout << "\nInput list or dlc file not valid. Please ensure that you have provided a valid input list and dlc for processing. Run snpe-sample with the -h flag for more details" << std::endl;
+		return nullptr;
+	}
+
+	// Check if given buffer type is valid
+	if (bufferTypeStr == "USERBUFFER_FLOAT")
+	{
+		bufferType = USERBUFFER_FLOAT;
+	}
+	else
+	{
+		std::cout << "\nBuffer type is not valid. Please run snpe-sample with the -h flag for more details" << std::endl;
+		return nullptr;
+	}
+
+	//Check if given user buffer source type is valid
+	int userBufferSourceType;
+
+	// CPUBUFFER / GLBUFFER supported only for USERBUFFER_FLOAT
+	if (bufferType == USERBUFFER_FLOAT)
+	{
+		if (userBufferSourceStr == "CPUBUFFER")
+		{
+			userBufferSourceType = CPUBUFFER;
+		}
+		else if (userBufferSourceStr == "GLBUFFER")
+		{
+			std::cout << "\nGLBUFFER mode is only supported on Android OS" << std::endl;
+			return nullptr;
+			userBufferSourceType = GLBUFFER;
+		}
+		else
+		{
+			std::cout
+				<< "\nSource of user buffer type is not valid. Please run snpe-sample with the -h flag for more details"
+				<< std::endl;
+			return nullptr;
+		}
+	}
+
+	if (staticQuantizationStr == "true")
+	{
+		staticQuantization = true;
+	}
+	else if (staticQuantizationStr == "false")
+	{
+		staticQuantization = false;
+	}
+	else
+	{
+		std::cout << "\nStatic quantization value is not valid. Please run snpe-sample with the -h flag for more details"
+			<< std::endl;
+		return nullptr;
+	}
+
+	//Check if both runtimelist and runtime are passed in
+	if (runtimeSpecified && (runtimeList.empty() == false))
+	{
+		std::cout << "\nInvalid option cannot mix runtime order -l with runtime -r " << std::endl;
+		std::exit(FAILURE);
+	}
+
+	if (runtimeSpecified)
+	{
+		runtime = checkRuntime(runtime, staticQuantization);
+		std::cout << "runtime is checked " << std::endl;
+	}
+
+	std::unique_ptr<zdl::DlContainer::IDlContainer> container = loadContainerFromFile(dlc);
+	if (container == nullptr)
+	{
+		std::cerr << "Error while opening the container file." << std::endl;
+		return nullptr;
+	}
+
+	useUserSuppliedBuffers = (bufferType == USERBUFFER_FLOAT ||
+		bufferType == USERBUFFER_TF8 ||
+		bufferType == USERBUFFER_TF16);
+
+	std::unique_ptr<zdl::SNPE::SNPE> snpe;
+	zdl::DlSystem::PlatformConfig platformConfig;
+
+	std::cout << "\nSettingbuilderoptions..................\n";
+	snpe = setBuilderOptions(container, runtime, runtimeList, useUserSuppliedBuffers, platformConfig, usingInitCaching);
+	return snpe;
+
+}
+int main()
 {
-    enum {UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16};
-    enum {CPUBUFFER, GLBUFFER};
-
-    // Command line arguments
-    static std::string dlc = "";
-    static std::string OutputDir = "./output/";
-    const char* inputFile = "";
-    std::string bufferTypeStr = "ITENSOR";
-    std::string userBufferSourceStr = "CPUBUFFER";
-    std::string staticQuantizationStr = "false";
-    static zdl::DlSystem::Runtime_t runtime = zdl::DlSystem::Runtime_t::CPU;
-    static zdl::DlSystem::RuntimeList runtimeList;
-    bool runtimeSpecified = false;
-    bool execStatus = false;
-    bool usingInitCaching = false;
-    bool staticQuantization = false;
-
-    // Process command line arguments
-     int opt = 0;
-    enum OPTIONS
-    {
-        OPT_HELP = 0,
-        OPT_CONTAINER = 1,
-        OPT_INPUT_LIST = 2,
-        OPT_OUTPUT_DIR = 3,
-        OPT_USERBUFFER = 4,
-        OPT_RUNTIME = 5,
-        OPT_RESIZABLE_DIM = 6,
-        OPT_INITBLOBSCACHE = 7,
-        OPT_RUNTIME_ORDER = 8,
-        OPT_STATIC_QUANTIZATION = 9,
-    };
-    static struct WinOpt::option long_options[] = {
-      {"help",                    WinOpt::no_argument,          NULL,  OPT_HELP},
-      {"container",               WinOpt::required_argument,    NULL,  OPT_CONTAINER},
-      {"input_list",              WinOpt::required_argument,    NULL,  OPT_INPUT_LIST},
-      {"output_dir",              WinOpt::required_argument,    NULL,  OPT_OUTPUT_DIR},
-      {"userbuffer",              WinOpt::required_argument,    NULL,  OPT_USERBUFFER},
-      {"runtime",                 WinOpt::required_argument,    NULL,  OPT_RUNTIME},
-      {"resizable_dim",           WinOpt::required_argument,    NULL,  OPT_RESIZABLE_DIM},
-      {"enable_init_cache",       WinOpt::no_argument,          NULL,  OPT_INITBLOBSCACHE},
-      {"runtime_order",           WinOpt::required_argument,    NULL,  OPT_RUNTIME_ORDER},
-      {"static_quantization",     WinOpt::required_argument,    NULL,  OPT_STATIC_QUANTIZATION},
-      {NULL,                      0,                  NULL,  0 }
-    };
-    int long_index = 0;
-    while ((opt = WinOpt::GetOptLongOnly(argc, argv, "", long_options, &long_index)) != -1)
-    {
-        switch (opt)
-        {
-            case OPT_HELP:
-                std::cout
-                        << "\nDESCRIPTION:\n"
-                        << "------------\n"
-                        << "Example application demonstrating how to load and execute a neural network\n"
-                        << "using the SNPE C++ API.\n"
-                        << "\n\n"
-                        << "REQUIRED ARGUMENTS:\n"
-                        << "-------------------\n"
-                        << "  --container  <FILE>   Path to the DL container containing the network.\n"
-                        << "  --input_list  <FILE>   Path to a file listing the inputs for the network.\n"
-                        << "  --output_dir  <PATH>   Path to directory to store output results.\n"
-                        << "\n"
-                        << "OPTIONAL ARGUMENTS:\n"
-                        << "-------------------\n"
-                        << "  --userbuffer  <TYPE>   Type of buffers to use [USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16] (" << bufferTypeStr << " is default).\n"
-                        << "  --static_quantization  <BOOL>    Specifies to use static quantization parameters from the model instead of input specific quantization [true, false]. Used in conjunction with USERBUFFER_TF8. \n"
-                        << "  --runtime  <RUNTIME> The runtime to be used [gpu, dsp, aip, cpu] (cpu is default). \n"
-                        << "  --resizable_dim  <NUMBER>  The maximum number that resizable dimensions can grow into. \n"
-                        << "                Used as a hint to create UserBuffers for models with dynamic sized outputs. Should be a positive integer and is not applicable when using ITensor. \n"
-                        << "  --enable_init_cache           Enable init caching to accelerate the initialization process of SNPE. Defaults to disable.\n"
-                        << "  --runtime_order  <VAL,VAL,VAL> Specifies the order of precedence for runtime e.g  cpu_float32, dsp_fixed8_tf etc. Valid values are:- \n"
-                        << "                    cpu_float32 (Snapdragon CPU)       = Data & Math: float 32bit \n"
-                        << "                    gpu_float32_16_hybrid (Adreno GPU) = Data: float 16bit Math: float 32bit \n"
-                        << "                    dsp_fixed8_tf (Hexagon DSP)        = Data & Math: 8bit fixed point Tensorflow style format \n"
-                        << "                    gpu_float16 (Adreno GPU)           = Data: float 16bit Math: float 16bit \n"
-                        << "                    cpu (Snapdragon CPU)               = Same as cpu_float32 \n"
-                        << "                    gpu (Adreno GPU)                   = Same as gpu_float32_16_hybrid \n"
-                        << "                    dsp (Hexagon DSP)                  = Same as dsp_fixed8_tf \n"
-                        << std::endl;
-
-                std::exit(SUCCESS);
-            case OPT_CONTAINER:
-                dlc = WinOpt::optarg;
-                break;
-            case OPT_INPUT_LIST:
-                inputFile = WinOpt::optarg;
-                break;
-            case OPT_OUTPUT_DIR:
-                OutputDir = WinOpt::optarg;
-                break;
-            case OPT_USERBUFFER:
-                bufferTypeStr = WinOpt::optarg;
-                break;
-            case OPT_RESIZABLE_DIM:
-                setResizableDim(atoi(WinOpt::optarg));
-                break;
-            case OPT_RUNTIME:
-                runtimeSpecified = true;
-                if (strcmp(WinOpt::optarg, "gpu") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::GPU;
-                }
-                else if (strcmp(WinOpt::optarg, "aip") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::AIP_FIXED8_TF;
-                }
-                else if (strcmp(WinOpt::optarg, "dsp") == 0)
-                {
-                    runtime = zdl::DlSystem::Runtime_t::DSP;
-                }
-                else if (strcmp(WinOpt::optarg, "cpu") == 0)
-                {
-                   runtime = zdl::DlSystem::Runtime_t::CPU;
-                }
-                else
-                {
-                   std::cerr << "The runtime option provide is not valid. Defaulting to the CPU runtime." << std::endl;
-
-                }
-                break;
-
-            case OPT_RUNTIME_ORDER:
-                {
-                   std::string inputString = WinOpt::optarg;
-                   //std::cout<<"Input String: "<<inputString<<std::endl;
-                   std::vector<std::string> runtimeStrVector;
-                   split(runtimeStrVector, inputString, ',');
-
-                   //Check for dups
-                   for(auto it = runtimeStrVector.begin(); it != runtimeStrVector.end()-1; it++)
-                   {
-                      auto found = std::find(it+1, runtimeStrVector.end(), *it);
-                      if(found != runtimeStrVector.end())
-                      {
-                         std::cerr << "Error: Invalid values passed to the argument "<< argv[WinOpt::optind-2] << ". Duplicate entries in runtime order" << std::endl;
-                         std::exit(FAILURE);
-                      }
-                   }
-
-                   runtimeList.clear();
-                   for(auto& runtimeStr : runtimeStrVector)
-                   {
-                      //std::cout<<runtimeStr<<std::endl;
-                      zdl::DlSystem::Runtime_t runtime = zdl::DlSystem::RuntimeList::stringToRuntime(runtimeStr.c_str());
-                      if(runtime != zdl::DlSystem::Runtime_t::UNSET)
-                      {
-                         bool ret = runtimeList.add(runtime);
-                         if(ret == false)
-                         {
-                            std::cerr <<zdl::DlSystem::getLastErrorString()<<std::endl;
-                            std::cerr << "Error: Invalid values passed to the argument "<< argv[WinOpt::optind-2] << ". Please provide comma seperated runtime order of precedence" << std::endl;
-                            std::exit(FAILURE);
-                         }
-                      }
-                      else
-                      {
-                         std::cerr << "Error: Invalid values passed to the argument "<< argv[WinOpt::optind-2] << ". Please provide comma seperated runtime order of precedence" << std::endl;
-                         std::exit(FAILURE);
-                      }
-                   }
-                }
-                break;
-
-            case OPT_INITBLOBSCACHE:
-               usingInitCaching = true;
-               break;
-
-            case OPT_STATIC_QUANTIZATION:
-               staticQuantizationStr = WinOpt::optarg;
-               break;
-
-            default:
-                std::cout << "Invalid parameter specified. Please run snpe-sample with the -h flag to see required arguments" << std::endl;
-                std::exit(FAILURE);
-        }
-    }
-
-    // Check if given arguments represent valid files
-    std::ifstream dlcFile(dlc);
-    std::ifstream inputList(inputFile);
-    if (!dlcFile || !inputList) {
-        std::cout << "Input list or dlc file not valid. Please ensure that you have provided a valid input list and dlc for processing. Run snpe-sample with the -h flag for more details" << std::endl;
-        return EXIT_FAILURE;
-    }
-
-    // Check if given buffer type is valid
-    int bufferType;
-    int bitWidth = 0;
-    if (bufferTypeStr == "USERBUFFER_FLOAT")
-    {
-        bufferType = USERBUFFER_FLOAT;
-    }
-    else if (bufferTypeStr == "USERBUFFER_TF8")
-    {
-        bufferType = USERBUFFER_TF8;
-        bitWidth = 8;
-    }
-    else if (bufferTypeStr == "USERBUFFER_TF16")
-    {
-        bufferType = USERBUFFER_TF16;
-        bitWidth = 16;
-    }
-    else if (bufferTypeStr == "ITENSOR")
-    {
-        bufferType = ITENSOR;
-    }
-    else
-    {
-        std::cout << "Buffer type is not valid. Please run snpe-sample with the -h flag for more details" << std::endl;
-        return EXIT_FAILURE;
-    }
-
-    //Check if given user buffer source type is valid
-    int userBufferSourceType;
-    // CPUBUFFER / GLBUFFER supported only for USERBUFFER_FLOAT
-    if (bufferType == USERBUFFER_FLOAT)
-    {
-        if( userBufferSourceStr == "CPUBUFFER" )
-        {
-            userBufferSourceType = CPUBUFFER;
-        }
-        else if( userBufferSourceStr == "GLBUFFER" )
-        {
-            std::cout << "GLBUFFER mode is only supported on Android OS" << std::endl;
-            return EXIT_FAILURE;
-            userBufferSourceType = GLBUFFER;
-        }
-        else
-        {
-            std::cout
-                  << "Source of user buffer type is not valid. Please run snpe-sample with the -h flag for more details"
-                  << std::endl;
-            return EXIT_FAILURE;
-        }
-    }
-
-   if (staticQuantizationStr == "true")
-   {
-      staticQuantization = true;
-   }
-   else if (staticQuantizationStr == "false")
-   {
-      staticQuantization = false;
-   }
-   else
-   {
-      std::cout << "Static quantization value is not valid. Please run snpe-sample with the -h flag for more details"
-                << std::endl;
-      return EXIT_FAILURE;
-   }
-
-    //Check if both runtimelist and runtime are passed in
-    if(runtimeSpecified && runtimeList.empty() == false)
-    {
-        std::cout << "Invalid option cannot mix runtime order -l with runtime -r " << std::endl;
-        std::exit(FAILURE);
-    }
-
-    if(runtimeSpecified)
-    {
-        runtime = checkRuntime(runtime, staticQuantization);
-    }
-
-    std::unique_ptr<zdl::DlContainer::IDlContainer> container = loadContainerFromFile(dlc);
-    if (container == nullptr)
-    {
-       std::cerr << "Error while opening the container file." << std::endl;
-       return EXIT_FAILURE;
-    }
-
-    bool useUserSuppliedBuffers = (bufferType == USERBUFFER_FLOAT ||
-                                   bufferType == USERBUFFER_TF8 ||
-                                   bufferType == USERBUFFER_TF16);
-
-    std::unique_ptr<zdl::SNPE::SNPE> snpe;
-    zdl::DlSystem::PlatformConfig platformConfig;
-
-    snpe = setBuilderOptions(container, runtime, runtimeList, useUserSuppliedBuffers, platformConfig, usingInitCaching);
-    if (snpe == nullptr)
-    {
-       std::cerr << "Error while building SNPE object." << std::endl;
-       return EXIT_FAILURE;
-    }
-    if (usingInitCaching)
-    {
-       if (container->save(dlc))
-       {
-          std::cout << "Saved container into archive successfully" << std::endl;
-       }
-       else
-       {
-          std::cout << "Failed to save container into archive" << std::endl;
-       }
-    }
-
-    // Check the batch size for the container
-    // SNPE 1.16.0 (and newer) assumes the first dimension of the tensor shape
-    // is the batch size.
-    zdl::DlSystem::TensorShape tensorShape;
-    tensorShape = snpe->getInputDimensions();
-    size_t batchSize = tensorShape.getDimensions()[0];
-    std::cout << "Batch size for the container is " << batchSize << std::endl;
-
-    // Open the input file listing and group input files into batches
-    std::vector<std::vector<std::string>> inputs = preprocessInput(inputFile, batchSize);
-
-    // Load contents of input file batches ino a SNPE tensor or user buffer,
-    // user buffer include cpu buffer and OpenGL buffer,
-    // execute the network with the input and save each of the returned output to a file.
-    if(useUserSuppliedBuffers)
-    {
-       // SNPE allows its input and output buffers that are fed to the network
-       // to come from user-backed buffers. First, SNPE buffers are created from
-       // user-backed storage. These SNPE buffers are then supplied to the network
-       // and the results are stored in user-backed output buffers. This allows for
-       // reusing the same buffers for multiple inputs and outputs.
-       zdl::DlSystem::UserBufferMap inputMap, outputMap;
-       std::vector <std::unique_ptr<zdl::DlSystem::IUserBuffer>> snpeUserBackedInputBuffers, snpeUserBackedOutputBuffers;
-       std::unordered_map <std::string, std::vector<uint8_t>> applicationOutputBuffers;
-
-       if( bufferType == USERBUFFER_TF8 || bufferType == USERBUFFER_TF16 )
-       {
-          createOutputBufferMap(outputMap, applicationOutputBuffers, snpeUserBackedOutputBuffers, snpe, true, bitWidth);
-
-          std::unordered_map <std::string, std::vector<uint8_t>> applicationInputBuffers;
-          createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe, true, staticQuantization, bitWidth);
-
-          for( size_t i = 0; i < inputs.size(); i++ )
-          {
-             // Load input user buffer(s) with values from file(s)
-             if( batchSize > 1 )
-                std::cout << "Batch " << i << ":" << std::endl;
-             if(!loadInputUserBufferTfN(applicationInputBuffers, snpe, inputs[i], inputMap, staticQuantization, bitWidth))
-             {
-                 return EXIT_FAILURE;
-             }
-             // Execute the input buffer map on the model with SNPE
-             execStatus = snpe->execute(inputMap, outputMap);
-             // Save the execution results only if successful
-             if (execStatus == true)
-             {
-                if(!saveOutput(outputMap, applicationOutputBuffers, OutputDir, i * batchSize, batchSize, true, bitWidth))
-                {
-                    return EXIT_FAILURE;
-                }
-
-             }
-             else
-             {
-                std::cerr << "Error while executing the network." << std::endl;
-             }
-          }
-       }
-       else if( bufferType == USERBUFFER_FLOAT )
-       {
-          createOutputBufferMap(outputMap, applicationOutputBuffers, snpeUserBackedOutputBuffers, snpe, false, bitWidth);
-
-          if( userBufferSourceType == CPUBUFFER )
-          {
-             std::unordered_map <std::string, std::vector<uint8_t>> applicationInputBuffers;
-             createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe, false, false, bitWidth);
-
-             for( size_t i = 0; i < inputs.size(); i++ )
-             {
-                // Load input user buffer(s) with values from file(s)
-                if( batchSize > 1 )
-                   std::cout << "Batch " << i << ":" << std::endl;
-                if(!loadInputUserBufferFloat(applicationInputBuffers, snpe, inputs[i]))
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the input buffer map on the model with SNPE
-                execStatus = snpe->execute(inputMap, outputMap);
-                // Save the execution results only if successful
-                if (execStatus == true)
-                {
-                   if(!saveOutput(outputMap, applicationOutputBuffers, OutputDir, i * batchSize, batchSize, false, bitWidth))
-                   {
-                       return EXIT_FAILURE;
-                   }
-                }
-                else
-                {
-                   std::cerr << "Error while executing the network." << std::endl;
-                }
-             }
-          }
-       }
-    }
-    else if(bufferType == ITENSOR)
-    {
-        // A tensor map for SNPE execution outputs
-        zdl::DlSystem::TensorMap outputTensorMap;
-        //Get input names and number
-        const auto& inputTensorNamesRef = snpe->getInputTensorNames();
-        if (!inputTensorNamesRef) throw std::runtime_error("Error obtaining Input tensor names");
-        const auto &inputTensorNames = *inputTensorNamesRef;
-
-        for (size_t i = 0; i < inputs.size(); i++) {
-            // Load input/output buffers with ITensor
-            if(batchSize > 1)
-                std::cout << "Batch " << i << ":" << std::endl;
-            if (inputTensorNames.size() == 1)
-            {
-                // Load input/output buffers with ITensor
-                std::unique_ptr<zdl::DlSystem::ITensor> inputTensor = loadInputTensor(snpe, inputs[i], inputTensorNames);
-                if(!inputTensor)
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the input tensor on the model with SNPE
-                execStatus = snpe->execute(inputTensor.get(), outputTensorMap);
-            }
-            else
-            {
-                std::vector<std::unique_ptr<zdl::DlSystem::ITensor>> inputTensors(inputTensorNames.size());
-                zdl::DlSystem::TensorMap inputTensorMap;
-                bool inputLoadStatus = false;
-                // Load input/output buffers with TensorMap
-                std::tie(inputTensorMap, inputLoadStatus) = loadMultipleInput(snpe, inputs[i], inputTensorNames, inputTensors);
-                if(!inputLoadStatus)
-                {
-                    return EXIT_FAILURE;
-                }
-                // Execute the multiple input tensorMap on the model with SNPE
-                execStatus = snpe->execute(inputTensorMap, outputTensorMap);
-            }
-            // Save the execution results if execution successful
-            if (execStatus == true)
-            {
-               if(!saveOutput(outputTensorMap, OutputDir, i * batchSize, batchSize))
-               {
-                   return EXIT_FAILURE;
-               }
-            }
-            else
-            {
-               std::cerr << "Error while executing the network." << std::endl;
-            }
-        }
-    }
-    // Freeing of snpe object
-    snpe.reset();
-    return SUCCESS;
+	// Initialize a ZeroMQ context
+	zmq::context_t context(1);
+
+	// Create a REP (reply) socket
+	zmq::socket_t socket(context, ZMQ_REP);
+	// zmq::socket_t socket(context, ZMQ_PULL);
+
+	// Bind the socket to a TCP address
+	std::string serverAddress = "tcp://*:5555";  // Replace with your desired address
+	socket.bind(serverAddress.c_str());
+
+
+	enum { UNKNOWN, USERBUFFER_FLOAT, USERBUFFER_TF8, ITENSOR, USERBUFFER_TF16 };
+	enum { CPUBUFFER, GLBUFFER };
+
+	std::unique_ptr<zdl::SNPE::SNPE> snpe;
+
+	// zmq::message_t first_msg;  //TODO: 5 is hardcoded
+	zmq::message_t infer_time_reply;
+	//struct timeval start_time, end_time;
+	//float seconds, useconds, milli_time;
+	useUserSuppliedBuffers = true; //TODO: hardcoded but take it from builder functions
+	const char* in_name;
+	const char* out_name;
+	size_t batchSize;
+	zdl::DlSystem::StringList outputNames;
+	zdl::DlSystem::StringList inputNames;
+	zdl::DlSystem::UserBufferMap inputMap, outputMap;
+	std::vector <std::unique_ptr<zdl::DlSystem::IUserBuffer>> snpeUserBackedInputBuffers, snpeUserBackedOutputBuffers;
+	std::unordered_map <std::string, std::vector<uint8_t>> applicationOutputBuffers;
+	std::unordered_map <std::string, std::vector<float>> applicationOutputBuffersFloat;
+
+	std::unordered_map <std::string, std::vector<uint8_t>> applicationInputBuffers;
+	std::unordered_map <std::string, std::vector<float>> applicationInputBuffersFloat;
+
+	while (true)
+	{
+		try{
+			std::vector<zmq::message_t> msgsfromserver;
+			msgsfromserver.clear();
+			//Waiting for first msg from client;
+			std::cout << "Waiting for first msg from socket:" << std::endl;
+			const auto ret = zmq::recv_multipart(socket, std::back_inserter(msgsfromserver));
+
+			//std::string receivedData_function = msgsfromserver[0].to_string();
+			//std::cout<<"#################"<<receivedData_function<<std::endl;
+
+			if (msgsfromserver[0].to_string() == "networkbuild")
+			{
+				//build network
+				std::cout << "\nBUILDING NETWORK" << std::endl;
+				//Read other required parameters;
+				// zmq::message_t msg1;
+				// zmq::message_t msg2;
+
+				// socket.recv(&msg1);
+				std::string dlc = msgsfromserver[1].to_string();  //dlc_name_socket;
+				std::cout << "received dlc name is: " << dlc << std::endl;
+
+				// std::cout<<"\nCurrent Working directory: "<<getCurrentDir()<<std::endl;
+
+				// socket.recv(&msg2);
+				std::string runtime_socket = msgsfromserver[2].to_string();
+				zdl::DlSystem::RuntimeList::stringToRuntime(runtime_socket.c_str());
+				std::cout << "received runtime: " << runtime_socket << std::endl;
+
+
+				std::string bufferTypeStr = "USERBUFFER_FLOAT"; //"ITENSOR"; shubham change
+				std::string userBufferSourceStr = "CPUBUFFER";
+				std::string staticQuantizationStr = "false";
+				static zdl::DlSystem::Runtime_t runtime; // = zdl::DlSystem::Runtime_t::CPU; //Shubham change cpu->DSP
+
+				bool runtimeSpecified = true;  //shubham change false -> true
+				bool usingInitCaching = false;
+
+				if (runtime_socket.compare("GPU") == 0)
+				{
+					runtime = zdl::DlSystem::Runtime_t::GPU;
+				}
+				else if (runtime_socket.compare("DSP") == 0)
+				{
+					runtime = zdl::DlSystem::Runtime_t::DSP;
+				}
+				else if (runtime_socket.compare("CPU") == 0)
+				{
+					runtime = zdl::DlSystem::Runtime_t::CPU;
+				}
+				else
+				{
+					std::cerr << "\nCorrect Runtime not specified, choosing default(CPU)" << std::endl;
+					runtime = zdl::DlSystem::Runtime_t::CPU;
+				}
+				// std::cout<<"\nmsg2.size(): "<<msg2.size()<<std::endl;
+
+
+				snpe = build_network(dlc, runtime, runtimeSpecified, usingInitCaching, bufferTypeStr, userBufferSourceStr, staticQuantizationStr);
+				
+				std::string build_status_str = "empty string";
+				
+				if (snpe == nullptr)
+				{
+					build_status_str = "Error while building SNPE object.";
+				}
+				else
+				{
+					zdl::DlSystem::TensorShape tensorShape;
+					tensorShape = snpe->getInputDimensions();
+					batchSize = tensorShape.getDimensions()[0];
+
+
+					outputNames = snpe->getOutputTensorNames();
+					out_name = outputNames.at(0);  //Only one output is present
+					std::cout << "shubham EXP: out_name: " << out_name;
+
+					//const auto& inputNamesOpt = snpe->getInputTensorNames();
+					inputNames = snpe->getInputTensorNames();
+					in_name = inputNames.at(0);  //Only one input is present
+
+
+					build_status_str = "build is successful";
+					// goto startwaiting;
+				}
+				
+				std::cout << build_status_str << std::endl;
+				zmq::message_t message(build_status_str.size());
+				memcpy(message.data(), build_status_str.c_str(), build_status_str.size());
+				socket.send(message);
+
+			}
+			else if (msgsfromserver[0].to_string() == "infer")
+			{
+				//make inference
+				bool execStatus = false;
+
+				if (snpe == nullptr)
+				{
+					std::cerr << "Error while building SNPE object." << std::endl;
+					std::string build_status_str = "Error while building SNPE object.";
+					zmq::message_t message(build_status_str.size());
+					memcpy(message.data(), build_status_str.c_str(), build_status_str.size());
+					socket.send(message);
+					continue;
+				}
+
+				std::cout << "\nMAKING INFERENCE" << std::endl;
+
+
+
+
+				// Check the batch size for the container
+				// SNPE 1.16.0 (and newer) assumes the first dimension of the tensor shape
+				// is the batch size.
+
+				// std::cout << "Batch size for the container is " << batchSize << std::endl;
+
+				// Open the input file listing and group input files into batches
+				// std::vector<std::vector<std::string>> inputs = preprocessInput(inputFile, batchSize);
+
+				try {
+					// std::cout << "Waiting for socket:"<<std::endl;
+					// zmq::message_t messages;
+					// socket.recv(&messages);
+
+					//std::vector<float> receivedData(static_cast<float*>(msgsfromserver[1].data()), static_cast<float*>(msgsfromserver[1].data()) + msgsfromserver[1].size() / sizeof(float));
+					std::vector<uint8_t> receivedData(static_cast<uint8_t*>(msgsfromserver[1].data()), static_cast<uint8_t*>(msgsfromserver[1].data()) + msgsfromserver[1].size());
+
+					// std::cout << "\n Size:" << messages.size() << "data: " << messages.data()<<std::endl;
+					// std::cout << "\n receivedData size" << receivedData.size()<<std::endl;
+
+						// SNPE allows its input and output buffers that are fed to the network
+						// to come from user-backed buffers. First, SNPE buffers are created from
+						// user-backed storage. These SNPE buffers are then supplied to the network
+						// and the results are stored in user-backed output buffers. This allows for
+						// reusing the same buffers for multiple inputs and outputs.
+
+
+
+
+							//std::cout << "userbuffer float" << std::endl;
+							// TODO: enable only One, done just for development ease
+					createOutputBufferMap(outputMap, applicationOutputBuffers, snpeUserBackedOutputBuffers, snpe, false, bitWidth);
+					//createOutputBufferMap(outputMap, applicationOutputBuffersFloat, snpeUserBackedOutputBuffers, snpe, false, bitWidth);
+					std::cout << "createOutputBufferMap done" << std::endl;
+
+
+					createInputBufferMap(inputMap, applicationInputBuffers, snpeUserBackedInputBuffers, snpe, false, false, bitWidth);
+					//createInputBufferMap(inputMap, applicationInputBuffersFloat, snpeUserBackedInputBuffers, snpe, false, false, bitWidth);
+					// std::cout << "createInputBufferMap done" << std::endl;
+
+
+
+
+					//applicationInputBuffersFloat.at(inputNames.at(0)) = receivedData;   //shubham change
+					applicationInputBuffers.at(inputNames.at(0)) = receivedData;   //shubham change
+					// std::cout << "wrote data" << std::endl;
+					// std::cout << "Received input" << std::endl;
+					for (size_t i = 0; i < batchSize; i++)
+					{
+						// Load input user buffer(s) with values from file(s)
+						if (batchSize > 1)
+							std::cout << "Batch " << i << ":" << std::endl;
+
+						auto start = std::chrono::high_resolution_clock::now();
+
+						// Execute the input buffer map on the model with SNPE
+						execStatus = snpe->execute(inputMap, outputMap);
+						auto end = std::chrono::high_resolution_clock::now();
+						auto infer_time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();
+						std::cout << "\nExecStatius: " << execStatus << std::endl;
+
+
+						std::cout << "Inference time:" << infer_time << std::endl;
+
+						std::string mill_str = std::to_string(infer_time);
+						infer_time_reply.rebuild(mill_str.size());
+						memcpy((void *) infer_time_reply.data(), (mill_str.c_str()), mill_str.size());
+
+						// Prepare the vectors(execution result) to be sent
+						 //std::vector<float> vector; // = applicationOutputBuffersFloat.at(out_name);
+						std::vector<uint8_t> vector; // = applicationOutputBuffers.at(out_name);
+						start = std::chrono::high_resolution_clock::now();
+						for (const char* outputName : outputNames)
+						{
+							std::cout << "\nOutputNames: " << outputName << std::endl;
+							//vector.insert(vector.end(), applicationOutputBuffersFloat.at(outputName).begin(), applicationOutputBuffersFloat.at(outputName).end());
+							vector.insert(vector.end(), applicationOutputBuffers.at(outputName).begin(), applicationOutputBuffers.at(outputName).end());
+
+						}
+						end = std::chrono::high_resolution_clock::now();
+						std::cout << "\nMerge time:" << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() << std::endl;
+
+						// Send the result
+						if (execStatus)
+						{
+							// std::cout << "execStatus is true"<<std::endl;
+							zmq::message_t message(vector.size());
+							std::cout << "Copying msg" << std::endl;
+
+							std::cout << "vector size: " << vector.size() << std::endl;
+							std::memcpy(message.data(), vector.data(), vector.size());
+							socket.send(message);
+							std::cout << "image sent" << std::endl;
+						}
+						else
+						{
+							std::cerr << "Error while executing the network." << std::endl;
+							//TODO: add bad msg here
+						}
+					}
+				}
+				catch (std::exception& e) {
+					std::cout << "ERROR: e: " << e.what() << std::endl;
+				}
+				// goto startwaiting;
+			}
+			 else if (msgsfromserver[0].to_string() == "get_infer_time")
+			 {
+				 std::cout<<"sending infertime:"<<std::endl;
+				 socket.send(infer_time_reply);
+				 std::cout << "message sent out" << std::endl;
+			 }
+			else
+			{
+				std::cerr << "Fist msg do not match" << std::endl;
+				std::cerr << "Message received: " << msgsfromserver[0] << std::endl;
+				// goto startwaiting;
+			}
+		}
+		catch (std::exception& e) {
+			std::cout << "Exception in snpe_sample: " << e.what() << std::endl;
+		}		
+	}
+
+	// Freeing of snpe object
+	snpe.reset();
+	return SUCCESS;
 }
