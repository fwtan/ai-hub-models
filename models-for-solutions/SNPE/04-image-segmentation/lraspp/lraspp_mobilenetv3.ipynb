{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e1ee76-7229-4154-8f68-8ec75ba5edd9",
   "metadata": {},
   "source": [
    "## Import necessary libraries and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0ed81-13cb-4ad7-a14a-a9b842da8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give appropriate permission to the directory \"FOLDER_WITH_ARTIFACTS\" you are working with\n",
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"input/raw\"\n",
    "os.environ['DLC32']=\"models/lraspp_fp32.dlc\"\n",
    "os.environ['DLC8']=\"models/lraspp_w8a16.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"input/input.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"lraspp\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #change with your device-id. Use command \"adb devices\" to get devices names.\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45ab72-b611-404b-8fd6-d7b640298e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models.segmentation as models\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad7983-0084-47d1-b1fe-1813bd6651e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.lraspp_mobilenet_v3_large(pretrained=True)\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self,pretrained_model):\n",
    "        super(CustomModel,self).__init__()\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.argmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output_dict = self.pretrained_model(x)\n",
    "        output = output_dict['out']\n",
    "        argmax_output = torch.argmax(output,dim=1,keepdim=False)\n",
    "        return argmax_output\n",
    "\n",
    "model = CustomModel(pretrained_model)\n",
    "input = torch.randn(1,3,400,400)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c13449-3ee0-413e-a424-2640d81ca997",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d4180-e2ef-496d-8d23-e875ca8a3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3, 400, 400).type(torch.FloatTensor).to('cpu')\n",
    "torch.onnx.export(model, dummy_input, \"./models/lraspp.onnx\",opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f7170-1db0-4597-841e-6506547adabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07173ba-596b-492a-a5cc-c258348c6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('input',exist_ok=True)\n",
    "os.makedirs('input/dataset',exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c35fb-5c8b-4e26-9899-2247de1bd3aa",
   "metadata": {},
   "source": [
    "## Download dataset in input/dataset/ directory\n",
    "\n",
    "User needs to download dataset of their choice before proceeding further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cac77-80a9-4df8-8fe5-d4dcff12fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'input/raw/'\n",
    "output_file_path = 'input/input.txt'  # The file where the output will be saved\n",
    "\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "# Filter only the .raw files and create a list of their names\n",
    "raw_files = [file for file in all_files if file.endswith('.raw')]\n",
    "raw_files = sorted(raw_files)\n",
    "# Write the file names to the output file\n",
    "with open(output_file_path, 'w') as f:\n",
    "    c=0\n",
    "    for raw_file in raw_files:\n",
    "        f.write(f\"./raw/{raw_file}\\n\")\n",
    "        c=c+1\n",
    "       \n",
    "\n",
    "print(f\"File names written to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bb5a9-166a-4687-a3cd-62355137da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc --input_network models/lraspp.onnx --output_path models/lraspp_fp32.dlc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c383a5-f64d-44c3-8208-a1d5b65e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "cd input/\n",
    "snpe-dlc-quantize --input_dlc ../models/lraspp_fp32.dlc --input_list input.txt  --axis_quant --output_dlc ../models/lraspp_mobilenet_v3_large_quant_w8a8.dlc  --enable_htp --htp_socs sm8550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58792696-c7c2-419e-9bb3-56e5213a47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "cd input/\n",
    "snpe-dlc-quantize --input_dlc ../models/lraspp_fp32.dlc --input_list input.txt  --axis_quant --output_dlc ../models/lraspp_w8a16.dlc  --act_bitwidth 16  --enable_htp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dbc88-89b1-4269-8476-afaebf54a8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-graph-prepare --input_dlc models/lraspp_fp32.dlc --output_dlc models/lraspp_fp16.dlc --use_float_io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fedfcf-9c0d-4021-91fa-996e7507313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0005f2-de81-42c5-bfa5-3c2f607ec761",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a9abe-c0b8-4982-872b-1713b1d9200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c10d4-ef2d-43d1-adbb-6418f77a47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#find ./raw -name *.raw > list.txt\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLC32 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC8 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $RAW_FILE_FOLDER /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d07758-dd3b-45e7-ae57-02eb06110537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=lraspp_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"lraspp\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list input.txt --output_dir $OUTPUT_FOLDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ce847-db91-4282-bb0d-1bd1819cbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_8b_DSP\n",
    "export OUTPUT_DLC_QUANTIZED8=lraspp_w8a16.dlc\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export ONDEVICE_FOLDER=\"lraspp\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "# modified the inputlist.txt. That's the only change\n",
    "snpe-net-run --container $OUTPUT_DLC_QUANTIZED8 --input_list input.txt --output_dir $OUTPUT_FOLDER --use_dsp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe729b0-902e-4f41-b17a-f11dfeba0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45d308-20d9-473a-9b5c-e30fa926eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247650d9-d56e-497a-a665-03d94c86ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_8b_DSP output/OUTPUT_8b_DSP\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU output/OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f4305-618f-4bf6-8478-1439beb79e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_overlay(image, segmented_image):\n",
    "    alpha = 1 # transparency for the original image\n",
    "    beta = 0.8 # transparency for the segmentation map\n",
    "    gamma = 0 # scalar added to each sum\n",
    "    # print(image.size)\n",
    "    # print(segmented_image.shape)\n",
    "    segmented_image = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR)\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.addWeighted(image, alpha, segmented_image, beta, gamma, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344c5b3-2523-4889-8086-dd6ee81c83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "crop_size = 400\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((crop_size,crop_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383f20d-3197-4658-83d1-5c30550a9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [\n",
    "               (0, 0, 0),  # background\n",
    "               (128, 0, 0), # aeroplane\n",
    "               (0, 128, 0), # bicycle\n",
    "               (128, 128, 0), # bird\n",
    "               (0, 0, 128), # boat\n",
    "               (128, 0, 128), # bottle\n",
    "               (0, 128, 128), # bus \n",
    "               (128, 128, 128), # car\n",
    "               (64, 0, 0), # cat\n",
    "               (192, 0, 0), # chair\n",
    "               (64, 128, 0), # cow\n",
    "               (192, 128, 0), # dining table\n",
    "               (64, 0, 128), # dog\n",
    "               (192, 0, 128), # horse\n",
    "               (64, 128, 128), # motorbike\n",
    "               (192, 128, 128), # person\n",
    "               (0, 64, 0), # potted plant\n",
    "               (128, 64, 0), # sheep\n",
    "               (0, 192, 0), # sofa\n",
    "               (128, 192, 0), # train\n",
    "               (0, 64, 128) # tv/monitor\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e32bc-8a32-4eb5-ad3b-ff3e4a45c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_labels(image, model, device):\n",
    "    # transform the image to tensor and load into computation device\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0) # add a batch dimension\n",
    "    outputs = model(image)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6fbbc-fe9b-46f1-a09d-66677b658c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_segmentation_map(outputs):\n",
    "    labels = outputs.detach().cpu().numpy()\n",
    "    # create Numpy arrays containing zeros\n",
    "    # later to be used to fill them with respective red, green, and blue pixels\n",
    "    red_map = np.zeros_like(labels).astype(np.uint8)\n",
    "    green_map = np.zeros_like(labels).astype(np.uint8)\n",
    "    blue_map = np.zeros_like(labels).astype(np.uint8)\n",
    "    \n",
    "    for label_num in range(0, len(label_map)):\n",
    "        index = labels == label_num\n",
    "        red_map[index] = np.array(label_map)[label_num, 0]\n",
    "        green_map[index] = np.array(label_map)[label_num, 1]\n",
    "        blue_map[index] = np.array(label_map)[label_num, 2]\n",
    "        \n",
    "    segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
    "    return segmentation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c52e4b-25bc-4023-8719-1ef497c0d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNames():\n",
    "    inputlist = open('input/input.txt', 'r')\n",
    "    Lines = inputlist.readlines()\n",
    "    count = 0\n",
    "    imageList = []\n",
    "    for line in Lines:\n",
    "        name = line.split(\"preproc_\",1)[1]\n",
    "        name = name.split('.')[0]\n",
    "        imageList.append(name)\n",
    "        count += 1\n",
    "    return imageList\n",
    "imageList = ImageNames()\n",
    "print((imageList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba800e6-d036-4889-b5f1-917a34a2c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40e33e-e46b-4291-b1b7-8f9ae603b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('output/model_prediction', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad558bd-54b8-4e57-82fb-cafc49da4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = # mention dataset path here\n",
    "from PIL import Image\n",
    "import cv2\n",
    "for i in range(0,len(imageList)):\n",
    "\n",
    "    image = Image.open(image_dir+imageList[i]+'.jpg')\n",
    "    # do forward pass and get the output dictionary\n",
    "    image  = image.resize((crop_size,crop_size))\n",
    "    # print(image.size)\n",
    "    outputs = get_segment_labels(image, model, device)\n",
    "    # get the data from the `out` key\n",
    "    # outputs = outputs['out']\n",
    "    # print(type(outputs))\n",
    "    # print(outputs.shape)\n",
    "    segmented_image = draw_segmentation_map(outputs[0])\n",
    "    print(image.size)\n",
    "    print(segmented_image.shape)\n",
    "    final_image = image_overlay(image, segmented_image)\n",
    "    # show the segmented image and save to disk\n",
    "    # cv2.imshow('Segmented image', final_image)\n",
    "    # cv2.waitKey(0)\n",
    "    cv2.imwrite(f\"output/model_prediction/{imageList[i]}.jpg\", final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe377f7-b9a8-4d48-8a3e-4a4c0b537edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PostProc(img_path, out_path,i):\n",
    "    res = np.fromfile(img_path, dtype=\"float32\")\n",
    "    res_reshape = res.reshape((1,400,400)).astype(np.float32)\n",
    "    model_img = torch.from_numpy(res_reshape)\n",
    "    segmented_image = draw_segmentation_map(model_img[0])\n",
    "    image = Image.open(image_dir+imageList[i]+'.jpg')\n",
    "    # do forward pass and get the output dictionary\n",
    "    image  = image.resize((crop_size,crop_size))\n",
    "    final_image = image_overlay(image, segmented_image)\n",
    "    cv2.imwrite(f\"{out_path}\", final_image)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d407324-addc-4d5b-b4c6-601b4f155a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('output/test_results', exist_ok=True)\n",
    "os.makedirs('output/test_results/32b_arm', exist_ok=True)\n",
    "os.makedirs('output/test_results/8b_dsp', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d05b3-dd99-4a58-8c11-108b2c58abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = \"output/OUTPUT_32b_CPU/\"\n",
    "image_dir = # mention dataset path here\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "for i in range(0,len(imageList)):\n",
    "    img_path = os.path.join(test_images_dir, 'Result_')\n",
    "    img_path = img_path+str(i)+'/732.raw'\n",
    "    out_path = 'output/test_results/32b_arm/'+imageList[i]+'_prediction_32b_arm.png'\n",
    "    PostProc(img_path, out_path,i)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cf6d4-841d-4ed7-bfce-4b3b75be0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = \"output/OUTPUT_8b_DSP/\"\n",
    "for i in range(0,len(imageList)):\n",
    "    img_path = os.path.join(test_images_dir, 'Result_')\n",
    "    img_path = img_path+str(i)+'/732.raw'\n",
    "    out_path = 'output/test_results/8b_dsp/'+imageList[i]+'_prediction_8b_dsp.png'\n",
    "    PostProc(img_path, out_path,i)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eb305-e30a-4792-8d04-518cdf7cb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(30, 100));\n",
    "import cv2\n",
    "for i in range(0, 5):\n",
    "    \n",
    "    original = cv2.imread('<mention dataset path here>'+imageList[i]+'.jpg')\n",
    "    original = cv2.resize(original, (513,513))\n",
    "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    ax = fig.add_subplot(28,4,4*i+1);\n",
    "    plt.imshow(original,cmap='gray');\n",
    "    ax.set_title('original image\\n');\n",
    "    ax.axis('off');\n",
    "    \n",
    "    pth_inf = cv2.imread('output/model_prediction/'+imageList[i]+'.jpg')\n",
    "    pth_inf = cv2.resize(pth_inf, (513,513))\n",
    "    # pth_inf = cv2.cvtColor(pth_inf, cv2.COLOR_BGR2RGB)\n",
    "    # pth_overlay = image_overlay(original, pth_inf)\n",
    "    ax = fig.add_subplot(28,4,4*i+2);\n",
    "    plt.imshow(pth_inf,cmap='gray');\n",
    "    ax.set_title('pth output\\n');\n",
    "    ax.axis('off');\n",
    "\n",
    "\n",
    "    arm_fp32= cv2.imread('output/test_results/32b_arm/'+imageList[i]+'_prediction_32b_arm.png')\n",
    "    # arm_fp32 = cv2.cvtColor(arm_fp32, cv2.COLOR_BGR2RGB)\n",
    "    # fp32_overlay = image_overlay(original, arm_fp32)\n",
    "    arm_fp32 = cv2.resize(arm_fp32, (513,513))\n",
    "    ax = fig.add_subplot(28,4,4*i+3);\n",
    "    plt.imshow(arm_fp32,cmap='gray');\n",
    "    ax.set_title('fp32 on ARM\\n');\n",
    "    ax.axis('off');\n",
    "\n",
    "    dsp= cv2.imread('output/test_results/8b_dsp/'+imageList[i]+'_prediction_8b_dsp.png')\n",
    "    # dsp_int8 = cv2.cvtColor(dsp_int8, cv2.COLOR_BGR2RGB)\n",
    "    # int8_overlay = image_overlay(original, dsp_int8)\n",
    "    # print(dsp)\n",
    "    ax = fig.add_subplot(28,4,4*i+4);\n",
    "    plt.imshow(dsp,cmap='gray');\n",
    "    ax.set_title('int8 on DSP\\n');\n",
    "    ax.axis('off');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
