{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12380c63",
   "metadata": {},
   "source": [
    "# Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef650b-cf22-43e4-b988-9ac826def509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give appropriate permission to the directory \"FOLDER_WITH_ARTIFACTS\" you are working with\n",
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/snpe/2.16.0.231029/\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"input/raw\"\n",
    "os.environ['DLC32']=\"models/xlsr_fp32.dlc\"\n",
    "os.environ['DLC8']=\"models/xlsr_w8a8.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"input/input.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"xlsr\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009a977-402c-449f-8e52-2b507f291097",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('utils', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc897578-810c-44ee-a6ce-7e6d523580b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/quic/aimet-model-zoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c981332-4eb2-45c6-be67-09b7e87a7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r xlsr.patch aimet-model-zoo\n",
    "cd aimet-model-zoo\n",
    "git apply xlsr.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b9333-c15f-4962-aa1e-860df9dd8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r aimet-model-zoo/aimet_zoo_torch/common/super_resolution/ utils/\n",
    "cp -r aimet-model-zoo/aimet_zoo_torch/common/downloader.py utils/super_resolution/\n",
    "cp -r aimet-model-zoo/aimet_zoo_torch/xlsr/model/ utils/\n",
    "rm -rf aimet-model-zoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f82600-a226-468e-8159-f38f5ada79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd utils\n",
    "touch __init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe259e-1b27-4c01-954a-808de13745d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model.model_definition import XLSR\n",
    "from utils.super_resolution.imresize import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55eb27-0ffb-488c-b3ca-a42dc4df9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = XLSR(\"xlsr_4x_w8a8\",scaling_factor=4)\n",
    "model_fp32.from_pretrained(quantized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e440d2-2496-4fb3-a5d9-56638d54a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok= True)\n",
    "os.makedirs('output', exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c3487-d8ce-487e-a48f-b3ccb7939e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dummy_input = torch.randn(1,3, 128, 128).type(torch.FloatTensor).to('cpu')\n",
    "torch.onnx.export(model_fp32, dummy_input, \"./models/xlsr.onnx\",opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e763d-d689-42be-bdd8-4763679a09a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc --input_network models/xlsr.onnx --output_path models/xlsr_fp32.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a3a1d",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "<ul>\n",
    "    <li>  Dataset link wget https://figshare.com/ndownloader/files/38256855  </li>\n",
    "<li>Below block will automatically download datsest, but in case if it fails please download from above link.</li>\n",
    "    <li> Recommended, to comment below code, if already downloaded dataset once.</li>\n",
    "    <ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://figshare.com/ndownloader/files/38256855\n",
    "unzip 38256855 -d input\n",
    "rm -rf 38256855\n",
    "rm -rf input/Set14/image_SRF_4\n",
    "rm -rf input/Set14/image_SRF_3\n",
    "mkdir input/raw\n",
    "find input/Set14/image_SRF_2 -name '*_LR*' -delete\n",
    "mv input/Set14/image_SRF_2/* input/Set14/\n",
    "rm -rf input/Set14/image_SRF_2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762f717",
   "metadata": {},
   "source": [
    "# Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cbe80-cf28-4a4d-b3f0-6d36fbfedfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths =  glob.glob(os.path.join(\"input/Set14/\", '*'))\n",
    "img_paths = sorted(img_paths)\n",
    "img_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6adc3-9df0-46a7-a38c-c925e6275003",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e019c37-fe81-4aaa-842c-a27698d8b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_WEIGHTS = torch.FloatTensor([65.481, 128.553, 24.966])\n",
    "def preprocess(img, scaling_factor=2):\n",
    "    lr_img, hr_img = create_hr_lr_pair(img, scaling_factor)\n",
    "\n",
    "    return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35873a5-55cb-477d-b5b9-ae5b359f514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hr_lr_pair(img, scaling_factor=2):\n",
    "    height, width = img.shape[0:2]\n",
    "\n",
    "    # Take the largest possible center-crop of it such that its dimensions are perfectly divisible by the scaling factor\n",
    "    x_remainder = width % (scaling_factor)\n",
    "    y_remainder = height % (scaling_factor)\n",
    "    left = x_remainder // 2\n",
    "    top = y_remainder // 2\n",
    "    right = left + (width - x_remainder)\n",
    "    bottom = top + (height - y_remainder)\n",
    "    hr_img = img[top:bottom, left:right]\n",
    "\n",
    "    hr_height, hr_width = hr_img.shape[0:2]\n",
    "\n",
    "    hr_img = np.array(hr_img, dtype='float32')\n",
    "    lr_img = imresize(hr_img, 1. / scaling_factor)  # equivalent to matlab's imresize\n",
    "    flag=0\n",
    "    lr_img = np.uint8(np.clip(lr_img, 0., 255.))  # this is to simulate matlab's imwrite operation\n",
    "    hr_img = np.uint8(hr_img)\n",
    "    lr_height, lr_width = lr_img.shape[0:2]\n",
    "\n",
    "    # Sanity check\n",
    "    assert hr_width == lr_width * scaling_factor and hr_height == lr_height * scaling_factor\n",
    "    lr_img = convert_image(lr_img, source='array', target='[0, 1]')\n",
    "    hr_img = convert_image(hr_img, source='array', target='[0, 1]')\n",
    "\n",
    "    return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20431195-1874-4b87-bf3d-54e7f376a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(img, source, target):\n",
    "    if source == 'array':\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).contiguous()#chw\n",
    "        img = img.to(dtype=torch.float32).div(255)\n",
    "    elif source == '[0, 1]':\n",
    "        img = torch.clamp(img, 0, 1)  # useful to post-process output of models that can overspill\n",
    "    \n",
    "    if target == '[0, 1]':\n",
    "        pass  # already in [0, 1]\n",
    "    elif target == 'y-channel':\n",
    "        img = torch.matmul(img.permute(0, 2, 3, 1), RGB_WEIGHTS.to(img.device)) + 16.\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275e2de-194e-4682-bcaf-984467126d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(img):\n",
    "    img = img.detach().cpu().numpy()\n",
    "    img = np.clip(255. * img, 0., 255.)\n",
    "    img = np.uint8(img)\n",
    "    img = img.transpose(1, 2, 0)#hwc\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd18eaf-123d-469d-8e86-8e24a42bb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(test_images_dir, scaling_factor=2):\n",
    "    # Input images for the model\n",
    "    INPUTS_LR = []\n",
    "\n",
    "    # Post-processed images for visualization\n",
    "    IMAGES_LR = []\n",
    "    IMAGES_HR = []\n",
    "    \n",
    "    # Load the test images\n",
    "    count=0\n",
    "    img_paths =  glob.glob(os.path.join(test_images_dir, '*'))\n",
    "    img_paths = sorted(img_paths)\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.resize(cv2.imread(img_path),[512,512],interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        lr_img, hr_img = preprocess(img, scaling_factor)#chw\n",
    "        INPUTS_LR.append(lr_img)#chw\n",
    "        IMAGES_LR.append(post_process(lr_img))#hwc\n",
    "        IMAGES_HR.append(post_process(hr_img))#hwc\n",
    "\n",
    "    return INPUTS_LR, IMAGES_LR, IMAGES_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = \"input/Set14\"\n",
    "INPUTS_LR, IMAGES_LR, IMAGES_HR = load_dataset(test_images_dir, scaling_factor=4)\n",
    "for i, img_lr in enumerate(INPUTS_LR):\n",
    "    img_lr = img_lr.cpu().detach().numpy()\n",
    "    img_lr = img_lr.astype(np.float32)\n",
    "    fid = open(\"input/raw/img\"+str(i)+ \".raw\", 'wb')\n",
    "    img_lr.tofile(fid)\n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd17b7-3a3f-42a0-a662-8df8a13f544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_LR[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db2108-45f9-4047-b2cc-f68bd9b6febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input/input.txt\", \"w\") as f:\n",
    "    for i in range(14):\n",
    "        file_path = f\"./raw/img{i}.raw\"\n",
    "        f.write(file_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d8c9c-e18d-4d20-a868-d55f267fe4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "cd input\n",
    "snpe-dlc-quantize --input_dlc ../models/xlsr_fp32.dlc --input_list input.txt --use_enhanced_quantizer --use_adjusted_weights_quantizer --axis_quant --output_dlc ../models/xlsr_w8a8.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4921976",
   "metadata": {},
   "source": [
    "# Post-process model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa25133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_sr(img):\n",
    "#     img = img.detach().cpu().numpy()\n",
    "    img = np.fromfile(img, np.float32)\n",
    "    img = img.reshape((3,512, 512)).astype(np.float32)\n",
    "    img = np.clip(255. * img, 0., 255.)\n",
    "    img = np.uint8(img)\n",
    "    img = img.transpose(1, 2, 0)#hwc\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94790c",
   "metadata": {},
   "source": [
    "# Method to calcualte PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4103113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(img_pred, img_true, data_range=255., eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute PSNR between super-resolved and original images.\n",
    "    \n",
    "    :param img_pred:\n",
    "        The super-resolved image obtained from the model\n",
    "    :param img_true:\n",
    "        The original high-res image\n",
    "    :param data_range:\n",
    "        Default = 255\n",
    "    :param eps:\n",
    "        Default = 1e-8\n",
    "    :return:\n",
    "        PSNR value\n",
    "    \"\"\"\n",
    "    err = (img_pred - img_true) ** 2\n",
    "    err = err.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "    return 10. * torch.log10((data_range ** 2) / (err + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_psnr(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate individual PSNR metric for each super-res and actual high-res image-pair.\n",
    "    \n",
    "    :param y_pred:\n",
    "        The super-resolved image from the model\n",
    "    :param y_true:\n",
    "        The original high-res image\n",
    "    :return:\n",
    "        The evaluated PSNR metric for the image-pair\n",
    "    \"\"\"\n",
    "    y_pred = y_pred.transpose(2, 0, 1)[None] / 255.\n",
    "    y_true = y_true.transpose(2, 0, 1)[None] / 255.\n",
    "\n",
    "    sr_img = convert_image(torch.FloatTensor(y_pred),\n",
    "                           source='[0, 1]',\n",
    "                           target='y-channel')\n",
    "    hr_img = convert_image(torch.FloatTensor(y_true),\n",
    "                           source='[0, 1]',\n",
    "                           target='y-channel')\n",
    "\n",
    "    return compute_psnr(sr_img, hr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_average_psnr(sr_images, hr_images):\n",
    "    \"\"\"\n",
    "    Evaluate the avg PSNR metric for all test-set super-res and high-res images.\n",
    "\n",
    "    :param sr_images:\n",
    "        The list of super-resolved images obtained from the model for the given test-images\n",
    "    :param hr_images:\n",
    "        The list of original high-res test-images\n",
    "    :return:\n",
    "        Average PSNR metric for all super-resolved and high-res test-set image-pairs\n",
    "    \"\"\"\n",
    "    psnr = []\n",
    "    for sr_img, hr_img in zip(sr_images, hr_images):\n",
    "        psnr.append(evaluate_psnr(sr_img, hr_img))\n",
    "\n",
    " \n",
    "\n",
    "    # Convert the list of tensor values to a tensor array\n",
    "    psnr_tensor = torch.cat(psnr)\n",
    "\n",
    " \n",
    "\n",
    "    # Calculate the mean of the tensor array\n",
    "    average_psnr = torch.mean(psnr_tensor)\n",
    "\n",
    "    return average_psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1687e",
   "metadata": {},
   "source": [
    "# Creating Bin and Lib Folder on Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80b847",
   "metadata": {},
   "source": [
    "# Pushing all Lib and Bin files onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6634e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf854eb",
   "metadata": {},
   "source": [
    "# Pushing Artifacts on to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#find ./raw -name *.raw > list.txt\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLC32 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC8 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $RAW_FILE_FOLDER /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd9588",
   "metadata": {},
   "source": [
    "# Inferencing 8 bit DLC on DSP Runtime\n",
    "Give name of DLC in OUTPUT_DLC_QUANTIZED8 and ondevice folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_8b_DSP\n",
    "export OUTPUT_DLC_QUANTIZED8=xlsr_w8a8.dlc\n",
    "export ONDEVICE_FOLDER=\"xlsr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_QUANTIZED8 --input_list input.txt --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ea4c5",
   "metadata": {},
   "source": [
    "# Inferencing 32b DLC on CPU Runtime\n",
    "Give name of DLC in OUTPUT_DLC_32 and ondevice folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=xlsr_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"xlsr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list input.txt --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c1af8",
   "metadata": {},
   "source": [
    "# Pulling Output folder generated on different precision and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf075ed-ae3f-400d-97b8-e75acc863a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf output/OUTPUT_8b_DSP\n",
    "rm -rf output/OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_8b_DSP output/OUTPUT_8b_DSP\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU output/OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b27e6",
   "metadata": {},
   "source": [
    "# Calculate PSNR\n",
    "* Pass path of two raw image in Argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c037ca-46aa-4dc8-95ca-e14b69d94ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for i in range(10):\n",
    "    val.append(IMAGES_HR[i])\n",
    "val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = [\"output/OUTPUT_8b_DSP/\",\"output/OUTPUT_32b_CPU\"]\n",
    "RGB_WEIGHTS = torch.FloatTensor([65.481, 128.553, 24.966])\n",
    "for j in range(0,len(folder)):\n",
    "    IMAGES_SR = []\n",
    "    for i in range(0,10):\n",
    "        IMAGES_SR.append(post_process_sr(folder[j]+\"/Result_\"+str(i)+\"/43.raw\"))\n",
    "    print(folder[j],\" (Average PSNR) :: \",evaluate_average_psnr(IMAGES_SR, IMAGES_HR))\n",
    "    print(\"\\n============================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(IMAGES_SR[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9d09-8de6-443e-b99f-1e10c1d00686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IMAGES_HR[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
