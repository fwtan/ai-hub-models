{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12380c63",
   "metadata": {},
   "source": [
    "# Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9ad17-0fe3-4982-b0d0-d8f187641cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give appropriate permission to the directory \"FOLDER_WITH_ARTIFACTS\" you are working with\n",
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/snpe/2.16.0.231029/\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"input/raw\"\n",
    "os.environ['DLC32']=\"models/srgan_fp32.dlc\"\n",
    "os.environ['DLC8']=\"models/srgan_w8a8.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"input/input.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"srgan\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4a5b8-78c0-4935-8583-44c079125549",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/andreas128/mmsr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee2808-b3d4-463b-af10-caeefc2a2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd mmsr \n",
    "git reset --hard a73b318f0f07feb6505ef5cb1abf0db33e33807a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac945d00-d3c1-4cdd-9d06-e38e8669d3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd mmsr\n",
    "git apply ../mmsr-changes.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32a089-da28-4e61-bbe8-284874b3efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/quic/aimet-model-zoo/\n",
    "cp -r srgan.patch aimet-model-zoo\n",
    "cd aimet-model-zoo\n",
    "git apply srgan.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb89fb1-a5fa-46f4-91a3-dea34a2d1ca4",
   "metadata": {},
   "source": [
    "## Steps to generate ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9067ab6-b34a-4171-a15a-921595b380be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r aimet-model-zoo/aimet_zoo_torch/srgan/evaluators/srgan_quanteval.py mmsr/\n",
    "rm -rf aimet-model-zoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ff871-3b61-47cc-8252-5e4c1b189108",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd mmsr/codes/\n",
    "touch __init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab608f72-b48f-4d33-8c4d-dbb687573a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd mmsr/\n",
    "python srgan_quanteval.py --mmsr-path '../mmsr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from math import ceil, floor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e440d2-2496-4fb3-a5d9-56638d54a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok= True)\n",
    "os.makedirs('output', exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fd637-e42c-416e-82fe-728bb0d7f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r mmsr/srgan.onnx models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ba477-6649-4c53-85ae-611b6bfb6ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e763d-d689-42be-bdd8-4763679a09a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc --input_network models/srgan.onnx --output_path models/srgan_fp32.dlc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a3a1d",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "<ul>\n",
    "    <li>  Dataset link wget https://figshare.com/ndownloader/files/38256855  </li>\n",
    "<li>Below block will automatically download datsest, but in case if it fails please download from above link.</li>\n",
    "    <li> Recommended, to comment below code, if already downloaded dataset once.</li>\n",
    "    <ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://figshare.com/ndownloader/files/38256855\n",
    "unzip 38256855 -d input\n",
    "rm -rf 38256855\n",
    "rm -rf input/Set14/image_SRF_4\n",
    "rm -rf input/Set14/image_SRF_3\n",
    "mkdir input/raw\n",
    "find input/Set14/image_SRF_2 -name '*_LR*' -delete\n",
    "mv input/Set14/image_SRF_2/* input/Set14/\n",
    "rm -rf input/Set14/image_SRF_2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762f717",
   "metadata": {},
   "source": [
    "# Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cbe80-cf28-4a4d-b3f0-6d36fbfedfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths =  glob.glob(os.path.join(\"input/Set14/\", '*'))\n",
    "img_paths = sorted(img_paths)\n",
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4bfe6-1eb9-4c12-bbda-1a1a8e96b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/quic/aimet-model-zoo/develop/aimet_zoo_torch/common/super_resolution/imresize.py'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('imresize.py', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print('done')\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6effdbc2-b0f2-401e-9276-512d82afeccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528f62f-8628-4010-94af-dc30f4516ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_WEIGHTS = torch.FloatTensor([65.481, 128.553, 24.966])\n",
    "from imresize import *\n",
    "def preprocess(img, scaling_factor=2):\n",
    "    lr_img, hr_img = create_hr_lr_pair(img, scaling_factor)\n",
    "\n",
    "    return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64def8-1471-4408-b9af-ff9d7944ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hr_lr_pair(img, scaling_factor=2):\n",
    "    height, width = img.shape[0:2]\n",
    "\n",
    "    # Take the largest possible center-crop of it such that its dimensions are perfectly divisible by the scaling factor\n",
    "    x_remainder = width % (scaling_factor)\n",
    "    y_remainder = height % (scaling_factor)\n",
    "    left = x_remainder // 2\n",
    "    top = y_remainder // 2\n",
    "    right = left + (width - x_remainder)\n",
    "    bottom = top + (height - y_remainder)\n",
    "    hr_img = img[top:bottom, left:right]\n",
    "\n",
    "    hr_height, hr_width = hr_img.shape[0:2]\n",
    "\n",
    "    hr_img = np.array(hr_img, dtype='float32')\n",
    "    lr_img = imresize(hr_img, 1. / scaling_factor)  # equivalent to matlab's imresize\n",
    "    flag=0\n",
    "    lr_img = np.uint8(np.clip(lr_img, 0., 255.))  # this is to simulate matlab's imwrite operation\n",
    "    hr_img = np.uint8(hr_img)\n",
    "    lr_height, lr_width = lr_img.shape[0:2]\n",
    "\n",
    "    # Sanity check\n",
    "    assert hr_width == lr_width * scaling_factor and hr_height == lr_height * scaling_factor\n",
    "    lr_img = convert_image(lr_img, source='array', target='[0, 1]')\n",
    "    hr_img = convert_image(hr_img, source='array', target='[0, 1]')\n",
    "\n",
    "    return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87550bcf-a8cf-454f-9db0-75d67b69f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(img, source, target):\n",
    "    if source == 'array':\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).contiguous()#chw\n",
    "        img = img.to(dtype=torch.float32).div(255)\n",
    "    elif source == '[0, 1]':\n",
    "        img = torch.clamp(img, 0, 1)  # useful to post-process output of models that can overspill\n",
    "    \n",
    "    if target == '[0, 1]':\n",
    "        pass  # already in [0, 1]\n",
    "    elif target == 'y-channel':\n",
    "        img = torch.matmul(img.permute(0, 2, 3, 1), RGB_WEIGHTS.to(img.device)) + 16.\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69e106-46e9-49de-bbc5-5a702b15cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(img):\n",
    "    img = img.detach().cpu().numpy()\n",
    "    img = np.clip(255. * img, 0., 255.)\n",
    "    img = np.uint8(img)\n",
    "    img = img.transpose(1, 2, 0)#hwc\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efab17b-342b-43bf-9def-b9fc80b7c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(test_images_dir, scaling_factor=2):\n",
    "    # Input images for the model\n",
    "    INPUTS_LR = []\n",
    "\n",
    "    # Post-processed images for visualization\n",
    "    IMAGES_LR = []\n",
    "    IMAGES_HR = []\n",
    "    \n",
    "    # Load the test images\n",
    "    count=0\n",
    "    img_paths =  glob.glob(os.path.join(test_images_dir, '*'))\n",
    "    img_paths = sorted(img_paths)\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.resize(cv2.imread(img_path),[512,512],interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        lr_img, hr_img = preprocess(img, scaling_factor)#chw\n",
    "        INPUTS_LR.append(lr_img)#chw\n",
    "        IMAGES_LR.append(post_process(lr_img))#hwc\n",
    "        IMAGES_HR.append(post_process(hr_img))#hwc\n",
    "\n",
    "    return INPUTS_LR, IMAGES_LR, IMAGES_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed304b6e-cd34-4064-a471-ddad10278445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf059f9e-ce60-4264-91c2-22a45b58edec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5beb0d-faa5-4bd7-bede-45ec131c5afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = \"input/Set14\"\n",
    "INPUTS_LR, IMAGES_LR, IMAGES_HR = load_dataset(test_images_dir, scaling_factor=4)\n",
    "for i, img_lr in enumerate(INPUTS_LR):\n",
    "    img_lr = img_lr.cpu().detach().numpy()\n",
    "    img_lr = img_lr.astype(np.float32)\n",
    "    fid = open(\"input/raw/img\"+str(i)+ \".raw\", 'wb')\n",
    "    img_lr.tofile(fid)\n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd17b7-3a3f-42a0-a662-8df8a13f544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(IMAGES_LR[0])\n",
    "plt.imshow(IMAGES_HR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db2108-45f9-4047-b2cc-f68bd9b6febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input/input.txt\", \"w\") as f:\n",
    "    for i in range(14):\n",
    "        file_path = f\"./raw/img{i}.raw\"\n",
    "        f.write(file_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d8c9c-e18d-4d20-a868-d55f267fe4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "cd input\n",
    "snpe-dlc-quantize --input_dlc ../models/srgan_fp32.dlc --input_list input.txt --use_enhanced_quantizer --use_adjusted_weights_quantizer --axis_quant --output_dlc ../models/srgan_w8a8.dlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455e1a5-51af-4e90-8dd9-993b62f52bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4921976",
   "metadata": {},
   "source": [
    "# Post-process model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa25133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_sr(img):\n",
    "#     img = img.detach().cpu().numpy()\n",
    "    img = np.fromfile(img, np.float32)\n",
    "    img = img.reshape((3,512, 512)).astype(np.float32)\n",
    "    img = np.clip(255. * img, 0., 255.)\n",
    "    img = np.uint8(img)\n",
    "    img = img.transpose(1, 2, 0)#hwc\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94790c",
   "metadata": {},
   "source": [
    "Method to calcualte PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4103113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(img_pred, img_true, data_range=255., eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute PSNR between super-resolved and original images.\n",
    "    \n",
    "    :param img_pred:\n",
    "        The super-resolved image obtained from the model\n",
    "    :param img_true:\n",
    "        The original high-res image\n",
    "    :param data_range:\n",
    "        Default = 255\n",
    "    :param eps:\n",
    "        Default = 1e-8\n",
    "    :return:\n",
    "        PSNR value\n",
    "    \"\"\"\n",
    "    err = (img_pred - img_true) ** 2\n",
    "    err = err.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "    return 10. * torch.log10((data_range ** 2) / (err + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_psnr(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate individual PSNR metric for each super-res and actual high-res image-pair.\n",
    "    \n",
    "    :param y_pred:\n",
    "        The super-resolved image from the model\n",
    "    :param y_true:\n",
    "        The original high-res image\n",
    "    :return:\n",
    "        The evaluated PSNR metric for the image-pair\n",
    "    \"\"\"\n",
    "    y_pred = y_pred.transpose(2, 0, 1)[None] / 255.\n",
    "    y_true = y_true.transpose(2, 0, 1)[None] / 255.\n",
    "\n",
    "    sr_img = convert_image(torch.FloatTensor(y_pred),\n",
    "                           source='[0, 1]',\n",
    "                           target='y-channel')\n",
    "    hr_img = convert_image(torch.FloatTensor(y_true),\n",
    "                           source='[0, 1]',\n",
    "                           target='y-channel')\n",
    "\n",
    "    return compute_psnr(sr_img, hr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_average_psnr(sr_images, hr_images):\n",
    "    \"\"\"\n",
    "    Evaluate the avg PSNR metric for all test-set super-res and high-res images.\n",
    "\n",
    "    :param sr_images:\n",
    "        The list of super-resolved images obtained from the model for the given test-images\n",
    "    :param hr_images:\n",
    "        The list of original high-res test-images\n",
    "    :return:\n",
    "        Average PSNR metric for all super-resolved and high-res test-set image-pairs\n",
    "    \"\"\"\n",
    "    psnr = []\n",
    "    for sr_img, hr_img in zip(sr_images, hr_images):\n",
    "        psnr.append(evaluate_psnr(sr_img, hr_img))\n",
    "        print(evaluate_psnr(sr_img, hr_img))\n",
    "\n",
    " \n",
    "\n",
    "    # Convert the list of tensor values to a tensor array\n",
    "    psnr_tensor = torch.cat(psnr)\n",
    "\n",
    " \n",
    "\n",
    "    # Calculate the mean of the tensor array\n",
    "    average_psnr = torch.mean(psnr_tensor)\n",
    "\n",
    "    return average_psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1687e",
   "metadata": {},
   "source": [
    "# Creating Bin and Lib Folder on Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80b847",
   "metadata": {},
   "source": [
    "# Pushing all Lib and Bin files onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6634e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf854eb",
   "metadata": {},
   "source": [
    "# Pushing Artifacts on to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#find ./raw -name *.raw > list.txt\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLC32 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC8 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $RAW_FILE_FOLDER /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd9588",
   "metadata": {},
   "source": [
    "# Inferencing 8 bit DLC on DSP Runtime\n",
    "Give name of DLC in OUTPUT_DLC_QUANTIZED8 and ondevice folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_8b_DSP\n",
    "export OUTPUT_DLC_QUANTIZED8=srgan_w8a8.dlc\n",
    "export ONDEVICE_FOLDER=\"srgan\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_QUANTIZED8 --input_list input.txt --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ea4c5",
   "metadata": {},
   "source": [
    "# Inferencing 32b DLC on CPU Runtime\n",
    "Give name of DLC in OUTPUT_DLC_32 and ondevice folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=srgan_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"srgan\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list input.txt --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c1af8",
   "metadata": {},
   "source": [
    "# Pulling Output folder generated on different precision and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf075ed-ae3f-400d-97b8-e75acc863a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf output/OUTPUT_8b_DSP\n",
    "rm -rf output/OUTPUT_32b_CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5bf2b-66d9-498a-9e24-8d0a227eff09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "# $DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_8b_DSP output/OUTPUT_8b_DSP\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU output/OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b27e6",
   "metadata": {},
   "source": [
    "# Calculate PSNR\n",
    "* Pass path of two raw image in Argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c037ca-46aa-4dc8-95ca-e14b69d94ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for i in range(10):\n",
    "    val.append(IMAGES_HR[i])\n",
    "val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff341bf7-5590-4a0e-9df6-cfadb807179d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = [\"output/OUTPUT_32b_CPU\"]\n",
    "RGB_WEIGHTS = torch.FloatTensor([65.481, 128.553, 24.966])\n",
    "for j in range(0,len(folder)):\n",
    "    IMAGES_SR = []\n",
    "    for i in range(0,13):\n",
    "        IMAGES_SR.append(post_process_sr(folder[j]+\"/Result_\"+str(i)+\"/155.raw\"))\n",
    "    print(folder[j],\" (Average PSNR) :: \",evaluate_average_psnr(IMAGES_SR, IMAGES_HR))\n",
    "    print(\"\\n============================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(IMAGES_SR[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9d09-8de6-443e-b99f-1e10c1d00686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IMAGES_HR[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
