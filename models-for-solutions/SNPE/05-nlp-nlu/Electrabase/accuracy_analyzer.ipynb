{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8b2366-147b-49b5-bfc5-bfa3948278e9",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b61f2-a5f0-4f9e-a3dd-ed4a40db4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"Electrabase\"\n",
    "os.environ['DLCFP16']=\"models/Electrabase_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/Electrabase_w16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/Electrabase_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"Electrabase_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5842b0-0ed6-4c95-9c51-1b47debf3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4dac8-2200-4ac3-b859-df0dabe991c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, ElectraForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/electra-base-squad2\")\n",
    "question_token={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d9896-63d8-491e-87e9-db2385cc4ebc",
   "metadata": {},
   "source": [
    "#### F1 Score calculation custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5373ca-8702-4268-b30f-a4ba2da5947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]   \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)  \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b2a7b-a26e-4f4e-9b26-61012d0b0665",
   "metadata": {},
   "source": [
    "### Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5da09-852f-4054-8088-44262ddf910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, ElectraForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/electra-base-squad2\")\n",
    "model = ElectraForQuestionAnswering.from_pretrained(\"bhadresh-savani/electra-base-squad2\")\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "question_answer={}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = int(tf.math.argmax(outputs.start_logits.detach().numpy(), axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(outputs.end_logits.detach().numpy(), axis=-1)[0])\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    print(question,tokenizer.decode(predict_answer_tokens, skip_special_tokens=True))\n",
    "    question_answer[question]=predicted_answer\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b88290-bd2f-40e4-9c08-60e9ebbac475",
   "metadata": {},
   "source": [
    "## Creating Directory on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f8e93-4ad5-4fb5-8ddf-dd1e891eb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9d6ea-5f4d-412a-98e5-a3bc3bf5b710",
   "metadata": {},
   "source": [
    "## Pushing All SNPE Lib and Bin folders onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b63e40-c2bb-4c47-96ba-88c12120be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2766ba-acbd-4b9c-bbc7-abf94b94ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d591d-22b2-437f-9a26-d830d1aabb52",
   "metadata": {},
   "source": [
    "## Pushing all Model Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28b07e-b128-4212-bd5d-691cb40d8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCFP16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCW16A16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push attention_mask /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push input_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push token_type_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940510f0-3eea-47a6-8df3-7dbb3eded975",
   "metadata": {},
   "source": [
    "## Inferencing FP32 Model on CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94531d9e-8171-4936-92aa-64f65781c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=Electrabase_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"Electrabase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list tf_raw_list.txt --set_unconsumed_as_output  --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c852c8d-4db9-474b-89c8-595ccc6f2b8d",
   "metadata": {},
   "source": [
    "## Inferencing FP16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218f493-b4e6-4fcc-b28a-3ba1afecc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_FP16\n",
    "export OUTPUT_FP_16=Electrabase_fp16.dlc\n",
    "export ONDEVICE_FOLDER=\"Electrabase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_FP_16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits   --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f908ae-c353-45fc-a2d1-71e6890e46d4",
   "metadata": {},
   "source": [
    "## Inferencing W16A16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea114a76-cb81-499d-a798-fbef36397d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W16A16\n",
    "export DLC_W16A16=Electrabase_w16a16_offline.dlc\n",
    "export ONDEVICE_FOLDER=\"Electrabase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W16A16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d8331-f071-40c1-8b51-1361e84f63a3",
   "metadata": {},
   "source": [
    "## Pulling the Output from Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d629db7-cb9c-407e-9d83-9a5591a55473",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W16A16 OUTPUT_DSP_W16A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_FP16 OUTPUT_DSP_FP16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3cc73-0bf3-4490-ac18-568791cde837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(start_logits,end_logits,inputs):\n",
    "    answer_start_index = int(tf.math.argmax(start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11462a34-bbdc-4779-ac78-833482cd2571",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0278e6-3065-464f-ba8d-a191dfc4ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_FP16\"]\n",
    "dlc_type = [\"fp32\",\"fp16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e450c-dcc9-424a-a513-b901ab3bf168",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs W16A16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d6ced-670b-4dd4-9ee2-ff762ff3d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W16A16\"]\n",
    "dlc_type = [\"fp32\",\"W16A16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c73248-2c4b-4b4b-a23d-b416f8724293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
