{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442bb43b-c36c-4db9-be5a-38ff4517c55a",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d700ca6-7af0-45e0-ad70-7bb06a9b13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"BertLarge\"\n",
    "os.environ['DLCFP16']=\"models/BertLarge_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/BertLarge_w16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/BertLarge_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"BertLarge_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7b340-ee40-46b2-9820-2ad431af38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7b452-d0e8-40b4-811c-0036cbf8ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-large-uncased-whole-word-masking-squad2\")\n",
    "question_token={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d847087-c1b5-4bb7-8e9d-bcd37e1c436e",
   "metadata": {},
   "source": [
    "#### F1 Score calculation custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd30d2-99a6-45a6-a62e-ec1fdde9e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]   \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)  \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f3828-72ec-498c-b1b2-c132dc97da4f",
   "metadata": {},
   "source": [
    "### Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a924423-5b09-4634-bc98-bd37e3e05494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "\n",
    "model_name = \"deepset/bert-large-uncased-whole-word-masking-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "question_answer={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = outputs.start_logits.argmax()\n",
    "    answer_end_index = outputs.end_logits.argmax()\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    question_answer[question]=predicted_answer\n",
    "    #print(\"predicted_answer\",predicted_answer,\"Actual Answer\",answer)\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b3aef-7f81-46fa-afc0-6623418be5a1",
   "metadata": {},
   "source": [
    "## Creating Directory on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f421a-c018-4b58-9ca0-d24a03617858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a40a57-88d0-4a4e-8357-3bd41765a3ec",
   "metadata": {},
   "source": [
    "## Pushing All SNPE Lib and Bin folders onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b1307-0a37-4886-8460-ae839b091779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95950ca-1747-4562-b325-c2520f02f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd867e-64ea-4f48-9ea3-61592bb3c20a",
   "metadata": {},
   "source": [
    "## Pushing all Model Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7adef-b53b-4e26-94dd-3f054772e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCFP16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCW16A16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push attention_mask /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push input_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push token_type_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46509a5c-0c86-467b-8d86-595d04a4d8d9",
   "metadata": {},
   "source": [
    "## Inferencing FP32 Model on CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bedb9c-22a6-4ae3-8c28-9f0d8086f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=BertLarge_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"BertLarge_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list tf_raw_list.txt --set_unconsumed_as_output  --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481bba9-e4ed-4e2f-b539-fee6d047cc1f",
   "metadata": {},
   "source": [
    "## Inferencing FP16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037aea4c-73b6-4170-90f7-6072b27d0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_FP16\n",
    "export OUTPUT_FP_16=BertLarge_fp16.dlc\n",
    "export ONDEVICE_FOLDER=\"BertLarge_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_FP_16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b9c0a-6efc-4499-a3bb-c8ebed097635",
   "metadata": {},
   "source": [
    "## Inferencing W16A16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3feae2-fde4-44de-a997-876c88bb1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W16A16\n",
    "export DLC_W16A16=BertLarge_w16a16_offline.dlc\n",
    "export ONDEVICE_FOLDER=\"BertLarge_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W16A16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd227e6b-f70b-402f-99d6-f30ee3651f25",
   "metadata": {},
   "source": [
    "## Pulling the Output from Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4510ae-1e31-4af2-9fb4-93984903e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W16A16 OUTPUT_DSP_W16A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_FP16 OUTPUT_DSP_FP16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca1266-8d89-4693-919e-51c0f5778e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(start_logits,end_logits,inputs):\n",
    "    answer_start_index = int(tf.math.argmax(start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa138dd8-85b8-48dd-bd1b-915cc2f21a25",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e7692-5850-410d-9889-e9d62cc22255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_FP16\"]\n",
    "dlc_type = [\"fp32\",\"fp16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1c67b-9cb5-4048-86ca-aa73fc514abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W16A16\"]\n",
    "dlc_type = [\"fp32\",\"W16A16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384b111-f3d5-415e-9905-92e8d0823d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
