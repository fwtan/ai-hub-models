{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fb0104-fcca-4c92-846f-15361e6d8bf5",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658edf27-a90f-4f43-9f81-2899f5ee50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"Distilbert\"\n",
    "os.environ['DLCFP16']=\"models/Distilbert_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/Distilbert_w16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/Distilbert_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"Distilbert_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8edebe3-603e-4ec6-961b-e83e5ff46bea",
   "metadata": {},
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a54b8-8e36-443a-8e59-7791f3a37fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0739b-fa9b-4f5b-aaaf-c730c630f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3211a-edc6-4508-9b17-226baf03b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optimum\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d929b-d365-48d9-89f0-27e6dc5222f2",
   "metadata": {},
   "source": [
    "## Converting the Model to ONNX format using optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fd96d-2e98-4d47-a7a7-5ecb762a1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "optimum-cli export onnx --model distilbert-base-uncased-distilled-squad models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b5b15-cde0-4036-bda3-dfc2f8df4e4b",
   "metadata": {},
   "source": [
    "### Getting Model Input name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c01ae3-8d82-441e-a88b-4ad837893370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "model_path='models/model.onnx'\n",
    "sess=onnxruntime.InferenceSession(model_path)\n",
    "input_layer_names=sess.get_inputs()\n",
    "for input_layer in input_layer_names:\n",
    "    print(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a16b9c-32e1-42f5-a6df-cc3b27d0c3cf",
   "metadata": {},
   "source": [
    "## Converting ONNX to FP32 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa75b00-bcaf-4a58-89c5-b7f40bc388d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc -i models/model.onnx -d input_ids 1,384 -d attention_mask 1,384 -o models/Distilbert_fp32.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dadb69-ede9-43ec-a520-c5c180c8d8ab",
   "metadata": {},
   "source": [
    "### Creating  the RAW Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d39a2a-0f69-4298-90fc-9920b2e86dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir input_ids\n",
    "mkdir attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f3b1a-4161-4e8a-b498-78065ded28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]  \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a980e-263a-4fee-93cc-855fc5622d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "question_answer={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    question_answer[question]=predicted_answer\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59af3d-a07c-444c-b486-2eb7330a21c6",
   "metadata": {},
   "source": [
    "## Creating List Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4619e4-d836-4ab2-a7da-eb501abd4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "question_token={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261fff17-e4a1-4dda-ae4d-9960a880e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <input_layer_name>:=<input_layer_path>[<space><input_layer_name>:=<input_layer_path>]\n",
    "total_iter = 30\n",
    "print(\"Generating input_list \\\"small_raw_list.txt\\\" with {} iterations\".format(total_iter))\n",
    "with open(\"tf_raw_list.txt\",'w') as f:\n",
    "    for i in range(total_iter):\n",
    "        f.write(\"input_ids:=input_ids/inp_ids_{}.raw attention_mask:=attention_mask/attn_mask_{}.raw\\n\".format(i,i)) # add token mask if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f92ac8-18c9-4567-9e95-e33808b028e6",
   "metadata": {},
   "source": [
    "## Creating W16A16 Precision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382733a6-ca6f-4997-bea5-5d74049eb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-quantize --input_dlc models/Distilbert_fp32.dlc --input_list tf_raw_list.txt --use_enhanced_quantizer --use_adjusted_weights_quantizer  --output_dlc models/Distilbert_w16a16.dlc --enable_htp --htp_socs sm8550 --weights_bitwidth 16 --act_bitwidth 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37858f-b527-4f3c-bb17-7c289cd00cc4",
   "metadata": {},
   "source": [
    "## Offline Preparation of W16A16 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54359fb6-c2c5-4ae2-9975-d0a708b1c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-graph-prepare --input_dlc models/Distilbert_w16a16.dlc --output_dlc models/Distilbert_w16a16_offline.dlc --set_output_tensors start_logits,end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39b1d4-740a-4e55-b156-1df0b374fefc",
   "metadata": {},
   "source": [
    "## Creating FP16 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9994394-b98e-4576-92fb-2f59edae892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-graph-prepare --input_dlc models/Distilbert_fp32.dlc --use_float_io --output_dlc models/Distilbert_fp16.dlc --set_output_tensors start_logits,end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7a960-2937-4946-a738-1dec31ca02e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
