{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0c79e6-b8a4-4f65-98a6-8a440ee653f2",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b750fa4-3be5-4c10-97bb-98b0274f386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"alberta\"\n",
    "os.environ['DLCFP16']=\"models/alberta_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/albertaw16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/alberta_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"alberta_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16c2ac-7942-49c7-a8ec-63d798f6da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9f9db-cbc7-460b-95ea-be33d1370e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "\n",
    "question_token={}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a4d23-d4ee-4f41-bc58-409cd4227e5d",
   "metadata": {},
   "source": [
    "#### F1 Score calculation custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a36d51-2e05-49d4-a4ef-21474adc1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]   \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)  \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f15be1-a4be-4348-b747-de4834850baa",
   "metadata": {},
   "source": [
    "### Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23ddde-74ba-43a6-8f0b-8f887303fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "model = AlbertForQuestionAnswering.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "question_answer={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = int(tf.math.argmax(outputs.start_logits.detach().numpy(), axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(outputs.end_logits.detach().numpy(), axis=-1)[0])\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    #print(question,tokenizer.decode(predict_answer_tokens, skip_special_tokens=True))\n",
    "    question_answer[question]=predicted_answer\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b41d6-f68a-40b8-9adf-11b9ea47bd5f",
   "metadata": {},
   "source": [
    "## Creating Directory on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd2ea0-286f-4581-a5ca-5c33809fa7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a991b-7fb7-41c5-adb2-5f2de930f58e",
   "metadata": {},
   "source": [
    "## Pushing All SNPE Lib and Bin folders onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3104960-f5fd-4a4e-b837-70159d5a5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc14097-16a4-4fd3-9807-88f45dddbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05319633-9abe-4390-8531-b15759c28cb4",
   "metadata": {},
   "source": [
    "## Pushing all Model Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7e2ad-a521-45e1-bf41-cebd4140aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCFP16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCW16A16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push attention_mask /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push input_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push token_type_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986ff07-180c-4420-864a-1d7f2300e36d",
   "metadata": {},
   "source": [
    "## Inferencing FP32 Model on CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0ae7f-a97c-4fd6-9595-eb099a0c8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=alberta_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"alberta_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list tf_raw_list.txt --set_unconsumed_as_output  --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338c2cf-0d2d-4f0c-babd-a511dc030902",
   "metadata": {},
   "source": [
    "## Inferencing FP16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e328cf9-6193-4419-b25b-9abda8f1be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_FP16\n",
    "export OUTPUT_FP_16=alberta_fp16.dlc\n",
    "export ONDEVICE_FOLDER=\"alberta_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_FP_16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits   --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188db51-9e65-4129-94eb-fe57de6ca50f",
   "metadata": {},
   "source": [
    "## Inferencing W16A16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bc4a5-3867-4473-aba7-bd395f7bca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W16A16\n",
    "export DLC_W16A16=albertaw16a16_offline.dlc\n",
    "export ONDEVICE_FOLDER=\"alberta_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W16A16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ec666-2ef5-4538-8678-52c058edd974",
   "metadata": {},
   "source": [
    "## Pulling the Output from Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04cfb4-e697-45d1-9b8d-1ca5a8472471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W16A16 OUTPUT_DSP_W16A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_FP16 OUTPUT_DSP_FP16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee1f53-76e8-45f7-a64e-8885d32e8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(start_logits,end_logits,inputs):\n",
    "    answer_start_index = int(tf.math.argmax(start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ecd52-b267-480b-8562-e0bd787cfaa5",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818f105-ba53-4565-9f09-d9a0b04b2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_FP16\"]\n",
    "dlc_type = [\"fp32\",\"fp16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140d406-f585-4bcf-bd68-bb1829a7527e",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs W16A16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0ddd4-38d4-4a04-9d40-82a50f2a3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W16A16\"]\n",
    "dlc_type = [\"fp32\",\"W16A16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
