{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e06ad8d-9571-488e-a157-4d2d39a2e645",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b37ec-bb78-400a-924a-15a263d55191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"BertBase\"\n",
    "os.environ['DLCFP16']=\"models/BertBase_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/BertBase_w16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/BertBase_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"BertBase_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfd8bf-128d-4253-9464-4a0591600d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bab2a-19b9-4ac5-89c1-c8d1f9157bcf",
   "metadata": {},
   "source": [
    "#### F1 Score calculation custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338db109-9951-4aef-8c43-a712c53ae6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]\n",
    "    \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee23d0-5106-487d-8d83-269ba2edb850",
   "metadata": {},
   "source": [
    "## Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7b5d0-fded-4f32-8a70-d56b00aad1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "question_answer={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = outputs.start_logits.argmax()\n",
    "    answer_end_index = outputs.end_logits.argmax()\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    question_answer[question]=predicted_answer\n",
    "    #print(\"predicted_answer\",predicted_answer,\"Actual Answer\",answer)\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115b4b1-2504-4ffa-aeff-2cd9c9a9cfbf",
   "metadata": {},
   "source": [
    "## Creating Directory on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200f6e7-4e6d-4fca-a055-86f0b9b9225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9fcae6-b813-4d8d-9094-ffbc5f972c73",
   "metadata": {},
   "source": [
    "## Pushing All SNPE Lib and Bin folders onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848acaaa-e417-4ae1-afec-c27eae28b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228966f0-8276-41f9-b48d-86710e4346b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf983696-3ac4-438b-b008-c5da4fa8b204",
   "metadata": {},
   "source": [
    "## Pushing all Model Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879ad38-cd38-4636-9f08-fad1adc4713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCFP16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCW16A16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push attention_mask /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push input_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push token_type_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5786375-0eb7-4139-85c2-9a6d6b7f201e",
   "metadata": {},
   "source": [
    "## Inferencing FP32 Model on CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f5df9-5e2c-4046-a5f4-7d4ce372b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=BertBase_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"BertBase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list tf_raw_list.txt --set_unconsumed_as_output  --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1451fb-7276-4936-9053-37d8412919a9",
   "metadata": {},
   "source": [
    "## Inferencing FP16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db3059-09d1-4478-9549-3c53da248b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_FP16\n",
    "export OUTPUT_FP_16=BertBase_fp16.dlc\n",
    "export ONDEVICE_FOLDER=\"BertBase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_FP_16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits  --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82704c1d-88a0-45f6-a39f-0645267945b2",
   "metadata": {},
   "source": [
    "## Inferencing W16A16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b4e1a-4a0b-4366-a8d4-3130f6df4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W16A16\n",
    "export DLC_W16A16=BertBase_w16a16_offline.dlc\n",
    "export ONDEVICE_FOLDER=\"BertBase_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W16A16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f273711-6ca7-461f-9ea6-ee94bb57aac1",
   "metadata": {},
   "source": [
    "## Pulling the Output from Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e9875-1118-4d03-b93d-2d4c08b4b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W16A16 OUTPUT_DSP_W16A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_FP16 OUTPUT_DSP_FP16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af9313-f180-4e51-b0f3-0c16457ff8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(start_logits,end_logits,inputs):\n",
    "    answer_start_index = int(tf.math.argmax(start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b21e9-960d-4476-87a2-ccc95d19f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "question_token={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)\n",
    "\n",
    "    token_type= inputs.token_type_ids\n",
    "    token_type=token_type.astype(np.float32)\n",
    "    with open(\"token_type_ids/token_type_id_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        token_type.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011316e-02bc-404c-a85a-f1ed5e77464b",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc05a29-11c4-49bf-8094-f8b99f286923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_FP16\"]\n",
    "dlc_type = [\"fp32\",\"fp16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ac4c8-37aa-4de5-887f-63db1e073987",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs W16A16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f980b59-da79-4265-b627-8694fc6ab764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W16A16\"]\n",
    "dlc_type = [\"fp32\",\"W16A16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4ab80-7dba-4eb1-b202-c1eb19112cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
