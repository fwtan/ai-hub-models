{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff16fcaa-8e97-44df-9a8e-7ca0064db049",
   "metadata": {},
   "source": [
    "## Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fe9b7-1f53-4070-af89-eb287a36b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/aditya/qaisw-v2.15.1.230926150623_62883\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"Distilbert\"\n",
    "os.environ['DLCFP16']=\"models/Distilbert_fp16.dlc\"\n",
    "os.environ['DLCW16A16']=\"models/Distilbert_w16a16_offline.dlc\"\n",
    "os.environ['DLCFP32']=\"models/Distilbert_fp32.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"tf_raw_list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"Distilbert_device\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"2dce6316\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f04c3-80d6-4125-b6c7-2302cebfac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path=\"dev-v2.0.json\"\n",
    "with open(data_path,\"r\") as f:\n",
    "    squad_data=json.load(f)\n",
    "context_qa_triples=[]\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            if qa['answers']:\n",
    "                answer=qa['answers'][0]['text']\n",
    "            elif qa['plausible_answers']:\n",
    "                plausible_answers=qa['plausible_answers']\n",
    "                answer=plausible_answers[0]['text']\n",
    "            else:\n",
    "                answer=''\n",
    "\n",
    "            context_qa_triples.append({'context':context,'question':question,'answers':answer})\n",
    "\n",
    "df=pd.DataFrame(context_qa_triples[:30])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e39486-bad5-41ee-8951-f04762cb227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "question_token={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    question_token[i]=[question,inputs,answer,text]\n",
    "    inp_ids = inputs.input_ids\n",
    "    inp_ids=inp_ids.astype(np.float32)\n",
    "    with open(\"input_ids/inp_ids_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        inp_ids.tofile(f)\n",
    "    \n",
    "    mask = inputs.attention_mask\n",
    "    mask=mask.astype(np.float32)\n",
    "    with open(\"attention_mask/attn_mask_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        mask.tofile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d0cea-518e-40a0-bd23-e04361024055",
   "metadata": {},
   "source": [
    "#### F1 Score calculation custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb36f0d-cd77-4d5d-96d0-1b27604a9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_scores_custom(prediction,ground_truth):\n",
    "    prediction_tokens=prediction.lower().split()\n",
    "    ground_truth_tokens=ground_truth.lower().split()\n",
    "    common_tokens=[token for token in prediction_tokens if token in ground_truth_tokens]   \n",
    "    if (len(prediction_tokens)==0 and len(ground_truth_tokens)==0):\n",
    "        return [1.0,1.0,1.0]\n",
    "    elif len(prediction_tokens)==0 or len(ground_truth_tokens)==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    precision=len(common_tokens)/len(prediction_tokens)\n",
    "    recall=len(common_tokens)/len(ground_truth_tokens)\n",
    "    if precision+recall==0:\n",
    "        return [0.0,0.0,0.0]\n",
    "    f1= 2*(precision*recall)/(precision+recall)  \n",
    "    return [f1,precision,recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e40cf2-49df-40d2-902d-37ae499724ec",
   "metadata": {},
   "source": [
    "### Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d8745-7e6b-447c-8200-c21c6944dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "question_answer={}\n",
    "for i in range(df.shape[0]):\n",
    "    question,text,answer=df.iloc[i].question,df.iloc[i].context,df.iloc[i].answers\n",
    "    inputs = tokenizer(question, text, return_tensors=\"np\",\n",
    "            padding='max_length',\n",
    "            truncation=\"longest_first\",\n",
    "            max_length=384)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
    "    \n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer=tokenizer.decode(predict_answer_tokens)\n",
    "    question_answer[question]=predicted_answer\n",
    "    f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "mean_f1_score=np.mean(f1_scores)\n",
    "mean_precision_score=np.mean(precision_scores)\n",
    "mean_recall_score=np.mean(recall_scores)\n",
    "mean_f1_score,mean_recall_score,mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5e31c-9a56-4fbe-bac2-2d5c51b9c804",
   "metadata": {},
   "source": [
    "## Creating Directory on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aafd6a-4921-4031-b9f5-28c7495da9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca37c56-57fc-4a06-baf1-b521ef1d3696",
   "metadata": {},
   "source": [
    "## Pushing All SNPE Lib and Bin folders onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c9acc-ee05-4378-9969-2763bd7286e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f397227-0cf9-4894-b690-490c755e61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede54514-8a1c-4e6c-91f2-5695201bc378",
   "metadata": {},
   "source": [
    "## Pushing all Model Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1bfbb-a479-4a48-b0e1-bd659be4569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCFP16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCW16A16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push attention_mask /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push input_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push token_type_ids /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb5339-d8ba-4c2d-b9a6-bcb864451579",
   "metadata": {},
   "source": [
    "## Inferencing FP32 Model on CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30643a0-2051-45f3-99c7-a113202ed5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=Distilbert_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"Distilbert_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list tf_raw_list.txt --set_unconsumed_as_output  --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d692a-04b4-4481-8fec-08b73856073e",
   "metadata": {},
   "source": [
    "## Inferencing FP16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bfe56-3d19-4c7b-97fb-0935ef67f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_FP16\n",
    "export OUTPUT_FP_16=Distilbert_fp16.dlc\n",
    "export ONDEVICE_FOLDER=\"Distilbert_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_FP_16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits   --output_dir $OUTPUT_FOLDER --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff7599-dfc1-470a-baf1-c3d7561648a4",
   "metadata": {},
   "source": [
    "## Inferencing W16A16 on DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f7442-a4c3-4184-a47a-1f50fa008c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W16A16\n",
    "export DLC_W16A16=Distilbert_w16a16_offline.dlc\n",
    "export ONDEVICE_FOLDER=\"Distilbert_device\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W16A16 --input_list tf_raw_list.txt --set_output_tensors start_logits,end_logits --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e92b49-0fab-4da8-a82d-f8c7c09a996b",
   "metadata": {},
   "source": [
    "## Pulling the Output from Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed8bc8-d5d1-47f4-9425-d63fc410f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W16A16 OUTPUT_DSP_W16A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_FP16 OUTPUT_DSP_FP16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c53f5-8209-4758-a25e-e49629011ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(start_logits,end_logits,inputs):\n",
    "    answer_start_index = int(tf.math.argmax(start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf05cbe-af95-4661-a6e0-b7b271617f6e",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc82af-ac9b-48fb-9744-3f703bd07f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_FP16\"]\n",
    "dlc_type = [\"fp32\",\"fp16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00c99d-8773-40e6-9e8a-184f53737d62",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of FP32 Vs W16A16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33f96a-01b2-4651-8755-9915329fdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W16A16\"]\n",
    "dlc_type = [\"fp32\",\"W16A16\"]\n",
    "data=[]\n",
    "f1_scores,precision_scores,recall_scores=[],[],[]\n",
    "for j in range(0,2):\n",
    "    print(\"-----------------------\",folder[j],\"-----------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            start_logits = np.fromfile(result_path+'/start_logits.raw', dtype=\"float32\")\n",
    "            end_logits=np.fromfile(result_path+'/end_logits.raw', dtype=\"float32\")\n",
    "            start_logits=start_logits.reshape((1,384))\n",
    "            end_logits=end_logits.reshape((1,384))\n",
    "            question,inputs,answer,text=question_token[int(result_path.split(\"/\")[1].split(\"_\")[1])]\n",
    "            predicted_answer=func(start_logits,end_logits,inputs)\n",
    "            data.append({\"Model_Type\":dlc_type[j],\"question\":question,\"predicted_answer\":predicted_answer,\"Actual Model Answer\":question_answer[question],\"answer\":answer,\"context\":text})\n",
    "            #f1,precision,recall=f1_scores_custom(predicted_answer,answer)\n",
    "            #f1_scores.append(f1)\n",
    "            #precision_scores.append(precision)\n",
    "            #recall_scores.append(recall)\n",
    "    \n",
    "    mean_f1_score=np.mean(f1_scores)\n",
    "    mean_precision_score=np.mean(precision_scores)\n",
    "    mean_recall_score=np.mean(recall_scores)\n",
    "    \n",
    "    print(\"F1_Score:\",mean_f1_score,\"Recall:\",mean_recall_score,\"Precision:\",mean_precision_score)\n",
    "data=pd.DataFrame(data)\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd5dab-38d7-4ac9-a05a-9d39a834a9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
